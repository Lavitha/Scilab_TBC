Total number of .sce files(without counting DEPENDENCIES directory): 93

grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.6.1/problem1.sce #
 
 to find the rank of matrix A   
 
 a  =
 
    1.  - 4.    9.   - 7.  
  - 1.    2.  - 4.     1.  
    5.  - 6.    10.    7.  
 
 p  =
 
    1.  - 4.    9.   - 7.  
  - 1.    2.  - 4.     1.  
    5.  - 6.    10.    7.  
 
 
 A=   
 
    1.  - 4.    9.   - 7.  
  - 1.    2.  - 4.     1.  
    5.  - 6.    10.    7.  
 
 
 performing row operations   
 
 a  =
 
    1.  - 4.    9.   - 7.  
    0.  - 2.    5.   - 6.  
    5.  - 6.    10.    7.  
 
 a  =
 
    1.  - 4.     9.   - 7.   
    0.  - 2.     5.   - 6.   
    0.    14.  - 35.    42.  
 
 
    1.  - 4.     9.   - 7.   
    0.  - 2.     5.   - 6.   
    0.    14.  - 35.    42.  
 
 a  =
 
    1.  - 4.    9.  - 7.  
    0.  - 2.    5.  - 6.  
    0.    0.    0.    0.  
 
 
    1.  - 4.    9.  - 7.  
    0.  - 2.    5.  - 6.  
    0.    0.    0.    0.  
 
 
 It is  that matrix A has 2 pivot columns   
 
 
 Hence, rank(A)=2   
 
 
 COlumns 1 and 2 are pivot columns   
 
 
 Hence, basis for C(A) is:   
 
  - 4.  
    2.  
  - 6.  
 
 and   
 
    1.  
  - 1.  
    5.  
 
 
 Basis for row space of A is:   
 
 
    0.  - 2.    5.  - 6.  
 
 and   
 
    1.  - 4.    9.  - 7.  
 
 
 To find the basis of N(A), solve Ax=0   
 
 
 on solving, we get the basis of N(A) as:   
 
 u  =
 
    1.   
    2.5  
    1.   
    0.   
 
 v  =
 
  - 5.  
  - 3.  
    0.  
    1.  
 
 
    1.   
    2.5  
    1.   
    0.   
 
 and   
 
  - 5.  
  - 3.  
    0.  
    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.1.13/1_1_13.sce #
 
 the augmented matrix is   
 
 a  =
 
    1.    0.  - 3.    8.  
    2.    2.    9.    7.  
    0.    1.    5.  - 2.  
 
 
    1.    0.  - 3.    8.  
    2.    2.    9.    7.  
    0.    1.    5.  - 2.  
 
 
 R2=R2-2*R1   
 
 a  =
 
    1.    0.  - 3.     8.  
    0.    2.    15.  - 9.  
    0.    1.    5.   - 2.  
 
 
    1.    0.  - 3.     8.  
    0.    2.    15.  - 9.  
    0.    1.    5.   - 2.  
 
 
 interchange R2 and R3   
 
 a  =
 
    1.    0.  - 3.     8.  
    0.    1.    5.   - 2.  
    0.    2.    15.  - 9.  
 
 
    1.    0.  - 3.     8.  
    0.    1.    5.   - 2.  
    0.    2.    15.  - 9.  
 
 
 R3=R3-2*R2   
 
 a  =
 
    1.    0.  - 3.    8.  
    0.    1.    5.  - 2.  
    0.    0.    5.  - 5.  
 
 
    1.    0.  - 3.    8.  
    0.    1.    5.  - 2.  
    0.    0.    5.  - 5.  
 
 
 R3=(1/5)*R3   
 
 a  =
 
    1.    0.  - 3.    8.  
    0.    1.    5.  - 2.  
    0.    0.    1.  - 1.  
 
 
    1.    0.  - 3.    8.  
    0.    1.    5.  - 2.  
    0.    0.    1.  - 1.  
 
 
 R2=R2-5*R3 and R1=R1+3*R3   
 
 a  =
 
    1.    0.  - 3.    8.  
    0.    1.    0.    3.  
    0.    0.    1.  - 1.  
 
 a  =
 
    1.    0.    0.    5.  
    0.    1.    0.    3.  
    0.    0.    1.  - 1.  
 
 
    1.    0.    0.    5.  
    0.    1.    0.    3.  
    0.    0.    1.  - 1.  
 
 s  =
 
    5.  
    3.  
  - 1.  
 
 
 solution is   
 
 
    5.  
    3.  
  - 1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.1.19/1_1_19.sce #
 
 the augmented matrix for h=2   
 
 a  =
 
    1.    2.    4.  
    3.    6.    8.  
 
 
    1.    2.    4.  
    3.    6.    8.  
 
 
 R2-2*R1   
 
 a  =
 
    1.    2.    4.  
    0.    0.  - 4.  
 
 
    1.    2.    4.  
    0.    0.  - 4.  
 
 
 from R3 we get 0=-4   
 
 
 hence, if h=2 no solution, else solution exists   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.1.1/1_1_1.sce #
 
 performing Gaussian elimination   
 
 a  =
 
    1.    5.  
  - 2.  - 7.  
 
 
 the co-efficient matrix is:   
 
 
    1.    5.  
  - 2.  - 7.  
 
 b  =
 
    7.  
  - 5.  
 
 c  =
 
    1.    5.    7.  
  - 2.  - 7.  - 5.  
 
 
 the augmented matrix is:   
 
 
    1.    5.    7.  
  - 2.  - 7.  - 5.  
 
 
 R2=R2+2*R1   
 
 c  =
 
    1.    5.    7.  
    0.    3.    9.  
 
 
    1.    5.    7.  
    0.    3.    9.  
 
 
 R2=(1/3)*R2   
 
 c  =
 
    1.    5.    7.  
    0.    1.    3.  
 
 
    1.    5.    7.  
    0.    1.    3.  
 
 
 R1=R1-5*R2   
 
 c  =
 
    1.    0.  - 8.  
    0.    1.    3.  
 
 
    1.    0.  - 8.  
    0.    1.    3.  
 
 x1  =
 
  - 8.  
 
 x2  =
 
    3.  
 
the solution is:x1=-8 x2=3 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.1.25/1_1_25.sce #
 
 the co-efficient matrix is:   
 
 a  =
 
    1.  - 4.    7.  
    0.    3.  - 5.  
  - 2.    5.  - 9.  
 
 
    1.  - 4.    7.  
    0.    3.  - 5.  
  - 2.    5.  - 9.  
 
 
 let g,h,k be the constants on RHS   
 
 
 R3=R3+2*R1   
 
 a  =
 
    1.  - 4.    7.  
    0.    3.  - 5.  
    0.  - 3.    5.  
 
 
    1.  - 4.    7.  
    0.    3.  - 5.  
    0.  - 3.    5.  
 
 
 the constants on RHS are:g,h,k+2g   
 
 
 R3=R3+R2   
 
 a  =
 
    1.  - 4.    7.  
    0.    3.  - 5.  
    0.    0.    0.  
 
 
    1.  - 4.    7.  
    0.    3.  - 5.  
    0.    0.    0.  
 
 
 the constants on RHS are:g,h,k+2g+h   
 
 
 for solution to exist   
 
 
 from R3:k+2g+h=0   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.1.7/1_1_7.sce #
 
 the augmented matrix is:   
 
 a  =
 
    1.    7.    3.  - 4.  
    0.    1.  - 1.    3.  
    0.    0.    0.    1.  
    0.    0.    1.  - 2.  
 
 
    1.    7.    3.  - 4.  
    0.    1.  - 1.    3.  
    0.    0.    0.    1.  
    0.    0.    1.  - 2.  
 
 
 interchange R3 and R4   
 
 a  =
 
    1.    7.    3.  - 4.  
    0.    1.  - 1.    3.  
    0.    0.    1.  - 2.  
    0.    0.    0.    1.  
 
 
    1.    7.    3.  - 4.  
    0.    1.  - 1.    3.  
    0.    0.    1.  - 2.  
    0.    0.    0.    1.  
 
 
 from R4 we get 0=1   
 
 
 hence, no solution   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.2.13/1_2_13.sce #
 
 the augmented matrix is   
 
 a  =
 
    1.  - 3.    0.  - 1.    0.  - 2.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
    1.  - 3.    0.  - 1.    0.  - 2.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
 R1=R1+R3   
 
 a  =
 
    1.  - 3.    0.    0.    9.    2.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
    1.  - 3.    0.    0.    9.    2.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
 R1=R1+3*R2   
 
 a  =
 
    1.    0.    0.    0.  - 3.    5.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
    1.    0.    0.    0.  - 3.    5.  
    0.    1.    0.    0.  - 4.    1.  
    0.    0.    0.    1.    9.    4.  
    0.    0.    0.    0.    0.    0.  
 
 
 corresponding equations are:   
 
 
 x1-3*x5=5, x2-4*x5=1, x4+9*x5=4, and 0=0   
 
 
 free variables:x3, x5   
 
 
 general solution is:   
 
 
 x1=5+3*x5, x2=1+4*x5, x3, x4=4-9*x5, x5   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.2.34/1_2_34.sce #
 
 the augmented matrix is:   
 
 
 
    1.    0.     0.      0.       0.        0.         0.    
    1.    2.     4.      8.       16.       32.        2.9   
    1.    4.     16.     64.      256.      1024.      14.8  
    1.    6.     36.     216.     1296.     7776.      39.6  
    1.    8.     64.     512.     4096.     32768.     74.3  
    1.    10.    100.    1000.    10000.    100000.    119.  
 
 
 performing row transformations   
 
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    1.    4.     16.     64.      256.      1024.      14.8  
    1.    6.     36.     216.     1296.     7776.      39.6  
    1.    8.     64.     512.     4096.     32768.     74.3  
    1.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    4.     16.     64.      256.      1024.      14.8  
    1.    6.     36.     216.     1296.     7776.      39.6  
    1.    8.     64.     512.     4096.     32768.     74.3  
    1.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    4.     16.     64.      256.      1024.      14.8  
    0.    6.     36.     216.     1296.     7776.      39.6  
    1.    8.     64.     512.     4096.     32768.     74.3  
    1.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    4.     16.     64.      256.      1024.      14.8  
    0.    6.     36.     216.     1296.     7776.      39.6  
    0.    8.     64.     512.     4096.     32768.     74.3  
    1.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    4.     16.     64.      256.      1024.      14.8  
    0.    6.     36.     216.     1296.     7776.      39.6  
    0.    8.     64.     512.     4096.     32768.     74.3  
    0.    10.    100.    1000.    10000.    100000.    119.  
 
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    4.     16.     64.      256.      1024.      14.8  
    0.    6.     36.     216.     1296.     7776.      39.6  
    0.    8.     64.     512.     4096.     32768.     74.3  
    0.    10.    100.    1000.    10000.    100000.    119.  
 
 
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    0.     8.      48.      224.      960.       9.    
    0.    6.     36.     216.     1296.     7776.      39.6  
    0.    8.     64.     512.     4096.     32768.     74.3  
    0.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    0.     8.      48.      224.      960.       9.    
    0.    0.     24.     192.     1248.     7680.      30.9  
    0.    8.     64.     512.     4096.     32768.     74.3  
    0.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.     0.      0.       0.        0.         0.    
    0.    2.     4.      8.       16.       32.        2.9   
    0.    0.     8.      48.      224.      960.       9.    
    0.    0.     24.     192.     1248.     7680.      30.9  
    0.    0.     48.     480.     4032.     32640.     62.7  
    0.    10.    100.    1000.    10000.    100000.    119.  
 a  =
 
    1.    0.    0.     0.      0.       0.        0.     
    0.    2.    4.     8.      16.      32.       2.9    
    0.    0.    8.     48.     224.     960.      9.     
    0.    0.    24.    192.    1248.    7680.     30.9   
    0.    0.    48.    480.    4032.    32640.    62.7   
    0.    0.    80.    960.    9920.    99840.    104.5  
 
 
    1.    0.    0.     0.      0.       0.        0.     
    0.    2.    4.     8.      16.      32.       2.9    
    0.    0.    8.     48.     224.     960.      9.     
    0.    0.    24.    192.    1248.    7680.     30.9   
    0.    0.    48.    480.    4032.    32640.    62.7   
    0.    0.    80.    960.    9920.    99840.    104.5  
 
 
 a  =
 
    1.    0.    0.     0.      0.       0.        0.     
    0.    2.    4.     8.      16.      32.       2.9    
    0.    0.    8.     48.     224.     960.      9.     
    0.    0.    0.     48.     576.     4800.     3.9    
    0.    0.    48.    480.    4032.    32640.    62.7   
    0.    0.    80.    960.    9920.    99840.    104.5  
 a  =
 
    1.    0.    0.     0.      0.       0.        0.     
    0.    2.    4.     8.      16.      32.       2.9    
    0.    0.    8.     48.     224.     960.      9.     
    0.    0.    0.     48.     576.     4800.     3.9    
    0.    0.    0.     192.    2688.    26880.    8.7    
    0.    0.    80.    960.    9920.    99840.    104.5  
 a  =
 
    1.    0.    0.    0.      0.       0.        0.    
    0.    2.    4.    8.      16.      32.       2.9   
    0.    0.    8.    48.     224.     960.      9.    
    0.    0.    0.    48.     576.     4800.     3.9   
    0.    0.    0.    192.    2688.    26880.    8.7   
    0.    0.    0.    480.    7680.    90240.    14.5  
 
 
    1.    0.    0.    0.      0.       0.        0.    
    0.    2.    4.    8.      16.      32.       2.9   
    0.    0.    8.    48.     224.     960.      9.    
    0.    0.    0.    48.     576.     4800.     3.9   
    0.    0.    0.    192.    2688.    26880.    8.7   
    0.    0.    0.    480.    7680.    90240.    14.5  
 
 a  =
 
    1.    0.    0.    0.      0.       0.        0.    
    0.    2.    4.    8.      16.      32.       2.9   
    0.    0.    8.    48.     224.     960.      9.    
    0.    0.    0.    48.     576.     4800.     3.9   
    0.    0.    0.    0.      384.     7680.   - 6.9   
    0.    0.    0.    480.    7680.    90240.    14.5  
 
 a  =
 
    1.    0.    0.    0.     0.       0.        0.    
    0.    2.    4.    8.     16.      32.       2.9   
    0.    0.    8.    48.    224.     960.      9.    
    0.    0.    0.    48.    576.     4800.     3.9   
    0.    0.    0.    0.     384.     7680.   - 6.9   
    0.    0.    0.    0.     1920.    42240.  - 24.5  
 
 
    1.    0.    0.    0.     0.       0.        0.    
    0.    2.    4.    8.     16.      32.       2.9   
    0.    0.    8.    48.    224.     960.      9.    
    0.    0.    0.    48.    576.     4800.     3.9   
    0.    0.    0.    0.     384.     7680.   - 6.9   
    0.    0.    0.    0.     1920.    42240.  - 24.5  
 
 a  =
 
    1.    0.    0.    0.     0.      0.       0.   
    0.    2.    4.    8.     16.     32.      2.9  
    0.    0.    8.    48.    224.    960.     9.   
    0.    0.    0.    48.    576.    4800.    3.9  
    0.    0.    0.    0.     384.    7680.  - 6.9  
    0.    0.    0.    0.     0.      3840.    10.  
 
 
    1.    0.    0.    0.     0.      0.       0.   
    0.    2.    4.    8.     16.     32.      2.9  
    0.    0.    8.    48.    224.    960.     9.   
    0.    0.    0.    48.    576.    4800.    3.9  
    0.    0.    0.    0.     384.    7680.  - 6.9  
    0.    0.    0.    0.     0.      3840.    10.  
 
 a  =
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     32.      2.9        
    0.    0.    8.    48.    224.    960.     9.         
    0.    0.    0.    48.    576.    4800.    3.9        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     32.      2.9        
    0.    0.    8.    48.    224.    960.     9.         
    0.    0.    0.    48.    576.    4800.    3.9        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 
 j  =
 
    0.    32.    960.    4800.    7680.  
 
 a  =
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     32.      2.9        
    0.    0.    8.    48.    224.    960.     9.         
    0.    0.    0.    48.    576.    4800.    3.9        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 a  =
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     0.       2.8166667  
    0.    0.    8.    48.    224.    960.     9.         
    0.    0.    0.    48.    576.    4800.    3.9        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 a  =
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     0.       2.8166667  
    0.    0.    8.    48.    224.    0.       6.5        
    0.    0.    0.    48.    576.    4800.    3.9        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 a  =
 
    1.    0.    0.    0.     0.      0.       0.         
    0.    2.    4.    8.     16.     0.       2.8166667  
    0.    0.    8.    48.    224.    0.       6.5        
    0.    0.    0.    48.    576.    0.     - 8.6        
    0.    0.    0.    0.     384.    7680.  - 6.9        
    0.    0.    0.    0.     0.      1.       0.0026042  
 a  =
 
    1.    0.    0.    0.     0.      0.    0.         
    0.    2.    4.    8.     16.     0.    2.8166667  
    0.    0.    8.    48.    224.    0.    6.5        
    0.    0.    0.    48.    576.    0.  - 8.6        
    0.    0.    0.    0.     384.    0.  - 26.9       
    0.    0.    0.    0.     0.      1.    0.0026042  
 
 
    1.    0.    0.    0.     0.      0.    0.         
    0.    2.    4.    8.     16.     0.    2.8166667  
    0.    0.    8.    48.    224.    0.    6.5        
    0.    0.    0.    48.    576.    0.  - 8.6        
    0.    0.    0.    0.     384.    0.  - 26.9       
    0.    0.    0.    0.     0.      1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.     0.      0.    0.         
    0.    2.    4.    8.     16.     0.    2.8166667  
    0.    0.    8.    48.    224.    0.    6.5        
    0.    0.    0.    48.    576.    0.  - 8.6        
    0.    0.    0.    0.     1.      0.  - 0.0700521  
    0.    0.    0.    0.     0.      1.    0.0026042  
 
 j  =
 
    0.    16.    224.    576.  
 
 a  =
 
    1.    0.    0.    0.     0.      0.    0.         
    0.    2.    4.    8.     0.      0.    3.9375     
    0.    0.    8.    48.    224.    0.    6.5        
    0.    0.    0.    48.    576.    0.  - 8.6        
    0.    0.    0.    0.     1.      0.  - 0.0700521  
    0.    0.    0.    0.     0.      1.    0.0026042  
 a  =
 
    1.    0.    0.    0.     0.      0.    0.         
    0.    2.    4.    8.     0.      0.    3.9375     
    0.    0.    8.    48.    0.      0.    22.191667  
    0.    0.    0.    48.    576.    0.  - 8.6        
    0.    0.    0.    0.     1.      0.  - 0.0700521  
    0.    0.    0.    0.     0.      1.    0.0026042  
 a  =
 
    1.    0.    0.    0.     0.    0.    0.         
    0.    2.    4.    8.     0.    0.    3.9375     
    0.    0.    8.    48.    0.    0.    22.191667  
    0.    0.    0.    48.    0.    0.    31.75      
    0.    0.    0.    0.     1.    0.  - 0.0700521  
    0.    0.    0.    0.     0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.     0.    0.    0.         
    0.    2.    4.    8.     0.    0.    3.9375     
    0.    0.    8.    48.    0.    0.    22.191667  
    0.    0.    0.    1.     0.    0.    0.6614583  
    0.    0.    0.    0.     1.    0.  - 0.0700521  
    0.    0.    0.    0.     0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.     0.    0.    0.         
    0.    2.    4.    0.     0.    0.  - 1.3541667  
    0.    0.    8.    48.    0.    0.    22.191667  
    0.    0.    0.    1.     0.    0.    0.6614583  
    0.    0.    0.    0.     1.    0.  - 0.0700521  
    0.    0.    0.    0.     0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.    0.    0.    0.         
    0.    2.    4.    0.    0.    0.  - 1.3541667  
    0.    0.    8.    0.    0.    0.  - 9.5583333  
    0.    0.    0.    1.    0.    0.    0.6614583  
    0.    0.    0.    0.    1.    0.  - 0.0700521  
    0.    0.    0.    0.    0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.    0.    0.    0.         
    0.    2.    4.    0.    0.    0.  - 1.3541667  
    0.    0.    1.    0.    0.    0.  - 1.1947917  
    0.    0.    0.    1.    0.    0.    0.6614583  
    0.    0.    0.    0.    1.    0.  - 0.0700521  
    0.    0.    0.    0.    0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.    0.    0.    0.         
    0.    2.    0.    0.    0.    0.    3.425      
    0.    0.    1.    0.    0.    0.  - 1.1947917  
    0.    0.    0.    1.    0.    0.    0.6614583  
    0.    0.    0.    0.    1.    0.  - 0.0700521  
    0.    0.    0.    0.    0.    1.    0.0026042  
 
 a  =
 
    1.    0.    0.    0.    0.    0.    0.         
    0.    1.    0.    0.    0.    0.    1.7125     
    0.    0.    1.    0.    0.    0.  - 1.1947917  
    0.    0.    0.    1.    0.    0.    0.6614583  
    0.    0.    0.    0.    1.    0.  - 0.0700521  
    0.    0.    0.    0.    0.    1.    0.0026042  
 
 
    1.    0.    0.    0.    0.    0.    0.         
    0.    1.    0.    0.    0.    0.    1.7125     
    0.    0.    1.    0.    0.    0.  - 1.1947917  
    0.    0.    0.    1.    0.    0.    0.6614583  
    0.    0.    0.    0.    1.    0.  - 0.0700521  
    0.    0.    0.    0.    0.    1.    0.0026042  
 
 v  =
 
    0.    1.7125  - 1.1947917    0.6614583  - 0.0700521    0.0026042  
 
 p  =
 
                        2            3            4            5  
    1.7125t - 1.1947917t + 0.6614583t - 0.0700521t + 0.0026042t   
 
 
 p(t)=   
 
 
                        2            3            4            5  
    1.7125t - 1.1947917t + 0.6614583t - 0.0700521t + 0.0026042t   
 
 
 p(7.5)=64.6 hundred lb   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.2.7/1_2_7.sce #
 
 the augmented matrix is   
 
 a  =
 
    1.    3.    4.    7.  
    3.    9.    7.    6.  
 
 
    1.    3.    4.    7.  
    3.    9.    7.    6.  
 
 
 R2=R2-3*R1   
 
 a  =
 
    1.    3.    4.    7.   
    0.    0.  - 5.  - 15.  
 
 
    1.    3.    4.    7.   
    0.    0.  - 5.  - 15.  
 
 
 (-1/5)*R2   
 
 a  =
 
    1.    3.    4.    7.  
    0.    0.    1.    3.  
 
 
    1.    3.    4.    7.  
    0.    0.    1.    3.  
 
 
 R1=R1-4*R2   
 
 a  =
 
    1.    3.    0.  - 5.  
    0.    0.    1.    3.  
 
 
 the row reduced form is:   
 
 
    1.    3.    0.  - 5.  
    0.    0.    1.    3.  
 
 
 corresponding equations are   
 
 
 x1+3*x2=-5 and x3=3   
 
 
 free variables:x2   
 
 
 general solution is:   
 
 
 x1=-5-3*x2, x2, x3=3   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.3.11/1_3_11.sce #
 
 vectors a1 a2 a3 are:   
 
 a1  =
 
    1.    0.  - 2.  
 
 
    1.  
    0.  
  - 2.  
 
 a2  =
 
  - 4.    3.    8.  
 
 
  - 4.  
    3.  
    8.  
 
 a3  =
 
    2.    5.  - 4.  
 
 
    2.  
    5.  
  - 4.  
 
 
 vector b=   
 
 b  =
 
    3.  - 7.  - 3.  
 
 
    3.  
  - 7.  
  - 3.  
 
 
 the augmented matrix is:   
 
 a  =
 
    1.  - 4.    2.    3.  
    0.    3.    5.  - 7.  
  - 2.    8.  - 4.  - 3.  
 
 
    1.  - 4.    2.    3.  
    0.    3.    5.  - 7.  
  - 2.    8.  - 4.  - 3.  
 
 a  =
 
    1.  - 4.    2.    3.  
    0.    3.    5.  - 7.  
    0.    0.    0.    3.  
 
 
    1.  - 4.    2.    3.  
    0.    3.    5.  - 7.  
    0.    0.    0.    3.  
 
 
 from the entries of last row, the system is inconsistent   
 
 
 hence, b is not a linear combination of a1 a2 and a3   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.3.1/1_3_1.sce #
 u  =
 
  - 1.  
    2.  
 
 
 u=   
 
 
  - 1.  
    2.  
 
 v  =
 
  - 3.  
  - 1.  
 
 
 v=   
 
 
  - 3.  
  - 1.  
 
 s  =
 
    5.  
    4.  
 
 
 u-2v=   
 
 
    5.  
    4.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.3.31/1_3_31.sce #
 
 1 gram at (0,1), 1 gram at (8,1) and 1 gram at (2,4)   
 
 cm  =
 
    3.3333333  
    2.         
 
 
 centre of mass is at   
 
 
    3.3333333  
    2.         
 
 
 the new weight of the system=9 grams   
 
 
 new centre of mass is at   
 
 s  =
 
    2.  
    2.  
 
 
    2.  
    2.  
 
 
 let w1,w2 and w3 be the weights added at (0,1),(8,1) and (2,4) respectively   
 
 
 hence, w1+w2+w3=6   
 
 
 using the formula for the centre of mass, we get   
 
 
 8*w2+2*w3=8 and w1+w2+4*w3=12   
 
 a  =
 
    1.    1.    1.    6.   
    0.    8.    2.    8.   
    1.    1.    4.    12.  
 
 
 the augmented matrix is:   
 
 
    1.    1.    1.    6.   
    0.    8.    2.    8.   
    1.    1.    4.    12.  
 
 
 R3=R3-R1   
 
 a  =
 
    1.    1.    1.    6.  
    0.    8.    2.    8.  
    0.    0.    3.    6.  
 
 
    1.    1.    1.    6.  
    0.    8.    2.    8.  
    0.    0.    3.    6.  
 
 
 R3=(1/3)*R3   
 
 a  =
 
    1.    1.    1.    6.  
    0.    8.    2.    8.  
    0.    0.    1.    2.  
 
 
    1.    1.    1.    6.  
    0.    8.    2.    8.  
    0.    0.    1.    2.  
 
 
 R2=R2-2*R3 and R1=R1-R3   
 
 a  =
 
    1.    1.    1.    6.  
    0.    8.    0.    4.  
    0.    0.    1.    2.  
 
 a  =
 
    1.    1.    0.    4.  
    0.    8.    0.    4.  
    0.    0.    1.    2.  
 
 
    1.    1.    0.    4.  
    0.    8.    0.    4.  
    0.    0.    1.    2.  
 
 
 R1=R1-(1/8)*R2   
 
 a  =
 
    1.    0.    0.    3.5  
    0.    8.    0.    4.   
    0.    0.    1.    2.   
 
 
    1.    0.    0.    3.5  
    0.    8.    0.    4.   
    0.    0.    1.    2.   
 
 
 R2=(1/8)*R2   
 
 a  =
 
    1.    0.    0.    3.5  
    0.    1.    0.    0.5  
    0.    0.    1.    2.   
 
 
    1.    0.    0.    3.5  
    0.    1.    0.    0.5  
    0.    0.    1.    2.   
 
Add 3.5 grams at (0,1), 0.5 grams at (8,1) and 2 grams at (2,4) 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.4.13/1_4_13.sce #
 
 the augmented matrix is:   
 
 a  =
 
    3.  - 5.    0.  
  - 2.    6.    4.  
    1.    1.    4.  
 
 
    3.  - 5.    0.  
  - 2.    6.    4.  
    1.    1.    4.  
 
 
 interchange R1 and R3   
 
 a  =
 
    1.    1.    4.  
  - 2.    6.    4.  
    3.  - 5.    0.  
 
 
    1.    1.    4.  
  - 2.    6.    4.  
    3.  - 5.    0.  
 
 
 R2=R2+2*R1 and R3=R3-3*R1   
 
 a  =
 
    1.    1.    4.   
    0.    8.    12.  
    3.  - 5.    0.   
 
 a  =
 
    1.    1.    4.   
    0.    8.    12.  
    0.  - 8.  - 12.  
 
 
    1.    1.    4.   
    0.    8.    12.  
    0.  - 8.  - 12.  
 
 
 R3=R3+R2   
 
 a  =
 
    1.    1.    4.   
    0.    8.    12.  
    0.    0.    0.   
 
 
    1.    1.    4.   
    0.    8.    12.  
    0.    0.    0.   
 
 
 from the entries of last row, the system is consistent   
 
 
 hence, u is in the plane spanned by the columns of a   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.4.7/1_4_7.sce #
 
 the three vectors are:   
 
 u  =
 
    4.  
  - 1.  
    7.  
  - 4.  
 
 v  =
 
  - 5.  
    3.  
  - 5.  
    1.  
 
 w  =
 
    7.  
  - 8.  
    0.  
    2.  
 
 
    4.  
  - 1.  
    7.  
  - 4.  
 
  - 5.  
    3.  
  - 5.  
    1.  
 
    7.  
  - 8.  
    0.  
    2.  
 
 
 u v and w form the columns of A   
 
 A  =
 
    4.  - 5.    7.  
  - 1.    3.  - 8.  
    7.  - 5.    0.  
  - 4.    1.    2.  
 
 
    4.  - 5.    7.  
  - 1.    3.  - 8.  
    7.  - 5.    0.  
  - 4.    1.    2.  
 
 
 the augmented matrix is:   
 
 c  =
 
    4.  - 5.    7.    6.  
  - 1.    3.  - 8.  - 8.  
    7.  - 5.    0.    0.  
  - 4.    1.    2.  - 7.  
 
 
    4.  - 5.    7.    6.  
  - 1.    3.  - 8.  - 8.  
    7.  - 5.    0.    0.  
  - 4.    1.    2.  - 7.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.5.11/1_5_11.sce #
 
 the augmented matrix is   
 
 a  =
 
    1.  - 4.  - 2.    0.    3.  - 5.    0.  
    0.    0.    1.    0.    0.  - 1.    0.  
    0.    0.    0.    0.  - 1.    4.    0.  
    0.    0.    0.    0.    0.    0.    0.  
 
 
    1.  - 4.  - 2.    0.    3.  - 5.    0.  
    0.    0.    1.    0.    0.  - 1.    0.  
    0.    0.    0.    0.  - 1.    4.    0.  
    0.    0.    0.    0.    0.    0.    0.  
 
 
 R1=R1-3*R3   
 
 a  =
 
    1.  - 4.  - 2.    0.    6.  - 17.    0.  
    0.    0.    1.    0.    0.  - 1.     0.  
    0.    0.    0.    0.  - 1.    4.     0.  
    0.    0.    0.    0.    0.    0.     0.  
 
 
    1.  - 4.  - 2.    0.    6.  - 17.    0.  
    0.    0.    1.    0.    0.  - 1.     0.  
    0.    0.    0.    0.  - 1.    4.     0.  
    0.    0.    0.    0.    0.    0.     0.  
 
 
 R1=R1+2*R2   
 
 a  =
 
    1.  - 4.    0.    0.    6.  - 19.    0.  
    0.    0.    1.    0.    0.  - 1.     0.  
    0.    0.    0.    0.  - 1.    4.     0.  
    0.    0.    0.    0.    0.    0.     0.  
 
 
    1.  - 4.    0.    0.    6.  - 19.    0.  
    0.    0.    1.    0.    0.  - 1.     0.  
    0.    0.    0.    0.  - 1.    4.     0.  
    0.    0.    0.    0.    0.    0.     0.  
 
 
 the free variables are:x2, x4 and x6   
 
 
 the basic variables are:x1, x3 and x5   
 
 
 the solution is:   
 
 
 [4*x2-5*x6  x2  x6  x4  4*x6  x6]   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.5.1/1_5_1.sce #
 
 the augmented matrix is:   
 
 a  =
 
    2.  - 5.    8.    0.  
  - 2.  - 7.    1.    0.  
    4.    2.    7.    0.  
 
 
    2.  - 5.    8.    0.  
  - 2.  - 7.    1.    0.  
    4.    2.    7.    0.  
 
 
 R2=R2+2*R1 and R3=R3-2*R1   
 
 a  =
 
    2.  - 5.     8.    0.  
    0.  - 12.    9.    0.  
    4.    2.     7.    0.  
 
 a  =
 
    2.  - 5.     8.    0.  
    0.  - 12.    9.    0.  
    0.    12.  - 9.    0.  
 
 
    2.  - 5.     8.    0.  
    0.  - 12.    9.    0.  
    0.    12.  - 9.    0.  
 
 
 R3=R3+R2   
 
 a  =
 
    2.  - 5.     8.    0.  
    0.  - 12.    9.    0.  
    0.    0.     0.    0.  
 
 
    2.  - 5.     8.    0.  
    0.  - 12.    9.    0.  
    0.    0.     0.    0.  
 
 
 only two columns have non zero pivots   
 
 
 hence, one column is a free column and therefore there exists a non trivial so 
      lution                                                                    
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.5.7/1_5_7.sce #
 
 the augmented matrix is:   
 
 a  =
 
    1.    3.  - 3.    7.    0.  
    0.    1.  - 4.    5.    0.  
 
 
    1.    3.  - 3.    7.    0.  
    0.    1.  - 4.    5.    0.  
 
 
 R1=R1-3*R2   
 
 a  =
 
    1.    0.    9.  - 8.    0.  
    0.    1.  - 4.    5.    0.  
 
 
    1.    0.    9.  - 8.    0.  
    0.    1.  - 4.    5.    0.  
 
 
 basic variables:x1 x2   
 
 
 free variables:x3 x4   
 
 
 x1=-9*x3+8*x4   
 
 
 x2=4*x3-5*x4   
 
 
 hence, solution is   
 
 
 [-9*x3+8*x4 4*x3-5*x4 x3 x4]   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.7.1/1_7_1.sce #
 
 given vectors u, v and w are   
 
 u  =
 
    5.  
    0.  
    0.  
 
 
    5.  
    0.  
    0.  
 
 v  =
 
    7.  
    2.  
  - 6.  
 
 
    7.  
    2.  
  - 6.  
 
 w  =
 
    9.  
    4.  
  - 8.  
 
 
    9.  
    4.  
  - 8.  
 
 
 the augmented matrix is   
 
 a  =
 
    5.    7.    9.    0.  
    0.    2.    4.    0.  
    0.  - 6.  - 8.    0.  
 
 
    5.    7.    9.    0.  
    0.    2.    4.    0.  
    0.  - 6.  - 8.    0.  
 
 
 R3=R3+3*R2   
 
 a  =
 
    5.    7.    9.    0.  
    0.    2.    4.    0.  
    0.    0.    4.    0.  
 
 
    5.    7.    9.    0.  
    0.    2.    4.    0.  
    0.    0.    4.    0.  
 
 
 there are no free variables   
 
 
 hence, the homogeneous equation has only trivial solution and  the vectors are 
       linearly independent                                                     
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH1/EX1.7.7/1_7_7.sce #
 
 the augmented matrix is   
 
 A  =
 
    1.  - 3.    3.  - 2.    0.  
  - 3.    7.  - 1.    2.    0.  
  - 4.  - 5.    7.    5.    0.  
 
 
    1.  - 3.    3.  - 2.    0.  
  - 3.    7.  - 1.    2.    0.  
  - 4.  - 5.    7.    5.    0.  
 
 
 since there are three rows, the maximum number of pivots can be 3   
 
 
 hence, at least one of the four variable must be free   
 
 
 so the equations have non trivial solution and the columns of A are linearly i 
      ndependent                                                                
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.1.1/2_1_1.sce #
 
 
 matrix A:   
 
 
    2.    0.  - 1.  
    4.  - 5.    2.  
 
 
 -2A=   
 
 
  - 4.    0.     2.  
  - 8.    10.  - 4.  
 
 
 matrix B   
 
 
 
    7.  - 5.    1.  
    1.  - 4.  - 3.  
 
 
 B-2A=   
 
 
    3.  - 5.    3.  
  - 7.    6.  - 7.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.2.1/2_2_1.sce #
 
 given matrix:   
 
 
 
    8.    6.  
    5.    4.  
 
 
 inverse of the matrix is:   
 
 
    2.   - 3.  
  - 2.5    4.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.2.7/2_2_7.sce #
 
 the co-efficient matrix is:   
 
 a  =
 
    1.    2.   
    5.    12.  
 
 
    1.    2.   
    5.    12.  
 
 
 inverse of the matrix is:   
 
 
    6.   - 1.   
  - 2.5    0.5  
 
 
 solution is:   
 
 
 
 
  - 9.  
    4.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.3.1/2_3_1.sce #
 
 the given matrix is:   
 
 
 
    5.    7.  
  - 3.  - 6.  
 
 
 the columns are lineraly independent   
 
 
 hence, by invertible matrix theorem   
 
 
 the matrix A is invertible   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.3.33/2_3_33.sce #
 
 matrix A corresponding to transformation T is:   
 
 
 
  - 5.    9.  
    4.  - 7.  
 
 
 determinant of A is:   
 
 
  - 1.  
 
 
 since det(A) is not equal to zero   
 
 
 by IMT, A is invertible   
 
 
 hence, the inverse of A exists   
 
 
 inverse of A is:   
 
 
    7.    9.  
    4.    5.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.4.25/2_4_25.sce #
 
 given matrix is:   
 
 
 
    1.    2.    0.    0.    0.  
    3.    5.    0.    0.    0.  
    0.    0.    2.    0.    0.  
    0.    0.    0.    7.    8.  
    0.    0.    0.    5.    6.  
 
 
 partitioning the matrix into 4 submatrices   
 
 A11  =
 
    1.    2.  
    3.    5.  
 
 
 A11=   
 
    1.    2.  
    3.    5.  
 
 A22  =
 
    2.    0.    0.  
    0.    7.    8.  
    0.    5.    6.  
 
 
 A22=   
 
    2.    0.    0.  
    0.    7.    8.  
    0.    5.    6.  
 
 A12  =
 
    0.    0.    0.  
    0.    0.    0.  
 
 
 A12=   
 
    0.    0.    0.  
    0.    0.    0.  
 
 A21  =
 
    0.    0.  
    0.    0.  
    0.    0.  
 
 
 A21=   
 
    0.    0.  
    0.    0.  
    0.    0.  
 
 
 partitioning A22 into 4 submatrices   
 
 A221  =
 
    2.  
 
 
    2.  
 
 B  =
 
    7.    8.  
    5.    6.  
 
 
 B=   
 
    7.    8.  
    5.    6.  
 
 
    0.    0.  
 
 
    0.  
    0.  
 
 
 determinant of B=   
 
 
    2.  
 
 
 Hence, B is invertible   
 
 
 inverse of B is   
 
 
    3.   - 4.   
  - 2.5    3.5  
 
 
 determinant of inverse of  B is:   
 
 
    0.5  
 
 
 hence the invese of A22 is:   
 
 
 
    0.5    0.     0.   
    0.     3.   - 4.   
    0.   - 2.5    3.5  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.5.13/2_5_13.sce #
 
 given matrix is:   
 
 a  =
 
    1.    3.  - 5.  - 3.  
  - 1.  - 5.    8.    4.  
    4.    2.  - 5.  - 7.  
  - 2.  - 4.    7.    5.  
 
 
 
    1.    3.  - 5.  - 3.  
  - 1.  - 5.    8.    4.  
    4.    2.  - 5.  - 7.  
  - 2.  - 4.    7.    5.  
 
 
 performing row operations   
 
 
 a  =
 
    1.    3.  - 5.  - 3.  
    0.  - 2.    3.    1.  
    4.    2.  - 5.  - 7.  
  - 2.  - 4.    7.    5.  
 
 a  =
 
    1.    3.   - 5.   - 3.  
    0.  - 2.     3.     1.  
    0.  - 10.    15.    5.  
  - 2.  - 4.     7.     5.  
 
 a  =
 
    1.    3.   - 5.   - 3.  
    0.  - 2.     3.     1.  
    0.  - 10.    15.    5.  
    0.    2.   - 3.   - 1.  
 
 
    1.    3.   - 5.   - 3.  
    0.  - 2.     3.     1.  
    0.  - 10.    15.    5.  
    0.    2.   - 3.   - 1.  
 
 p42  =
 
  - 1.  
 
 a  =
 
    1.    3.  - 5.  - 3.  
    0.  - 2.    3.    1.  
    0.    0.    0.    0.  
    0.    2.  - 3.  - 1.  
 
 a  =
 
    1.    3.  - 5.  - 3.  
    0.  - 2.    3.    1.  
    0.    0.    0.    0.  
    0.    0.    0.    0.  
 
 
    1.    3.  - 5.  - 3.  
    0.  - 2.    3.    1.  
    0.    0.    0.    0.  
    0.    0.    0.    0.  
 
 
 thus, lower triangular matrix is:   
 
 L  =
 
    1.    0.    0.    0.  
  - 1.    1.    0.    0.  
    4.    5.    1.    0.  
  - 2.  - 1.    0.    1.  
 
 
 L=   
 
    1.    0.    0.    0.  
  - 1.    1.    0.    0.  
    4.    5.    1.    0.  
  - 2.  - 1.    0.    1.  
 
 
 Upper triangular matrix is:   
 
 
 U=   
 
    1.    3.  - 5.  - 3.  
    0.  - 2.    3.    1.  
    0.    0.    0.    0.  
    0.    0.    0.    0.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.5.1/2_5_1.sce #
 
 the lower triangular matrix is:   
 
 
 
    1.    0.    0.  
  - 1.    1.    0.  
    2.  - 5.    1.  
 
 
 the upper triangular matrix is:   
 
 
 
    3.  - 7.  - 2.  
    0.  - 2.  - 1.  
    0.    0.  - 1.  
 
 
 the RHS of the equations are   
 
 
 
  - 7.  
    5.  
    2.  
 
 
 combining matrices L and b   
 
 
 
    1.    0.    0.  - 7.  
  - 1.    1.    0.    5.  
    2.  - 5.    1.    2.  
 
 
 performing row operations   
 
 
 R2=R2+R1   
 
 c  =
 
    1.    0.    0.  - 7.  
    0.    1.    0.  - 2.  
    2.  - 5.    1.    2.  
 
 
    1.    0.    0.  - 7.  
    0.    1.    0.  - 2.  
    2.  - 5.    1.    2.  
 
 
 R3=R3-2*R1   
 
 c  =
 
    1.    0.    0.  - 7.   
    0.    1.    0.  - 2.   
    0.  - 5.    1.    16.  
 
 
    1.    0.    0.  - 7.   
    0.    1.    0.  - 2.   
    0.  - 5.    1.    16.  
 
 
 R3=R3+5*R2   
 
 c  =
 
    1.    0.    0.  - 7.  
    0.    1.    0.  - 2.  
    0.    0.    1.    6.  
 
 
    1.    0.    0.  - 7.  
    0.    1.    0.  - 2.  
    0.    0.    1.    6.  
 
 y  =
 
  - 7.  
  - 2.  
    6.  
 
 
 y=   
 
  - 7.  
  - 2.  
    6.  
 
 
 combining U and y   
 
 
 
    3.  - 7.  - 2.  - 7.  
    0.  - 2.  - 1.  - 2.  
    0.    0.  - 1.    6.  
 
 
 performing row operations   
 
 
 R3=R3/-6   
 
 d  =
 
    3.  - 7.  - 2.  - 7.  
    0.  - 2.  - 1.  - 2.  
    0.    0.    1.  - 6.  
 
 
    3.  - 7.  - 2.  - 7.  
    0.  - 2.  - 1.  - 2.  
    0.    0.    1.  - 6.  
 
 
 R2=R2+R3 and R1=R1+2*R3   
 
 d  =
 
    3.  - 7.  - 2.  - 7.  
    0.  - 2.    0.  - 8.  
    0.    0.    1.  - 6.  
 
 d  =
 
    3.  - 7.    0.  - 19.  
    0.  - 2.    0.  - 8.   
    0.    0.    1.  - 6.   
 
 
    3.  - 7.    0.  - 19.  
    0.  - 2.    0.  - 8.   
    0.    0.    1.  - 6.   
 
 
 R1=R1-3.5*R2   
 
 d  =
 
    3.    0.    0.    9.  
    0.  - 2.    0.  - 8.  
    0.    0.    1.  - 6.  
 
 
    3.    0.    0.    9.  
    0.  - 2.    0.  - 8.  
    0.    0.    1.  - 6.  
 
 
 R1=R1/3 and R2=R2/-2   
 
 d  =
 
    1.    0.    0.    3.  
    0.  - 2.    0.  - 8.  
    0.    0.    1.  - 6.  
 
 d  =
 
    1.    0.    0.    3.  
    0.    1.    0.    4.  
    0.    0.    1.  - 6.  
 
 
    1.    0.    0.    3.  
    0.    1.    0.    4.  
    0.    0.    1.  - 6.  
 
 
 the solution is:   
 
 x  =
 
    3.  
    4.  
  - 6.  
 
 
 x=   
 
    3.  
    4.  
  - 6.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.5.7/2_5_7.sce #
 
 given matrix is:   
 
 a  =
 
    2.    5.  
  - 3.  - 4.  
 
 
 
    2.    5.  
  - 3.  - 4.  
 
 
 performing row operations   
 
 a  =
 
    2.    5.   
    0.    3.5  
 
 
    2.    5.   
    0.    3.5  
 
 
    2.    5.   
    0.    3.5  
 
 
 thus, the upper triangular matrix is   
 
 
 
 U=   
 
    2.    5.   
    0.    3.5  
 
 
 the lower triangular matrix is:   
 
 
 
 L=   
 
    1.     0.  
  - 1.5    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.6.1/2_6_1.sce #
 
 the consumption matrix is:   
 
 
 
    0.1    0.6    0.6  
    0.3    0.2    0.   
    0.3    0.1    0.1  
 
 
 Assuming that agriculture plans to produce 100 units and other units produce n 
      othing                                                                    
 
 
 the production vector is given by   
 
 
 
 x=   
 
    0.    
    100.  
    0.    
 
 
 thus the intermediate demand is:   
 
 
    60.  
    20.  
    10.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.6.7/2_6_7.sce #
 
 the consumption matrix is:   
 
 
 
    0.     0.5  
    0.6    0.2  
 
 
 the demand for 1 unit of output sector 1   
 
 d1  =
 
    1.  
    0.  
 
 
    1.  
    0.  
 
 
 the production required to satisfy demand d1 is:   
 
 x1  =
 
    1.6  
    1.2  
 
 
 x1=   
 
    1.6  
    1.2  
 
 
 the final demand is:   
 
 d2  =
 
    51.  
    30.  
 
 
 d2=   
 
    51.  
    30.  
 
 
 the production required to satisfy demand d2 is:   
 
 x2  =
 
    111.6  
    121.2  
 
 
 x2=   
 
    111.6  
    121.2  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.7.1/2_7_1.sce #
 
 consider the matrix   
 
 a  =
 
    1.    0.25    0.  
    0.    1.      0.  
    0.    0.      1.  
 
 
    1.    0.25    0.  
    0.    1.      0.  
    0.    0.      1.  
 
 
 consider a vector   
 
 x  =
 
    6.  
    8.  
    0.  
 
 
    6.  
    8.  
    0.  
 
 
 the effect of the matric on the vector is:   
 
 
    8.  
    8.  
    0.  
 
 
 now consider the matrix:   
 
 b  =
 
    1.    0.25  
    0.    1.    
 
 
    1.    0.25  
    0.    1.    
 
 
 considering the same vector   
 
 x1  =
 
    6.  
    8.  
 
 
    6.  
    8.  
 
 
 the effect of the new matrix on the vector is:   
 
 
    8.  
    8.  
 
 
 thus we can see that the two matrices have the same effect on vectors   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.7.7/2_7_7.sce #
 
 the matrix in R2 to rotate a vector by 60 degrees is:   
 
 a  =
 
    0.5        - 0.8660254  
    0.8660254    0.5        
 
 
    0.5        - 0.8660254  
    0.8660254    0.5        
 
 x  =
 
    6.  
    8.  
 
 
 x=   
 
    6.  
    8.  
 
 
 so the 3X3 matrix for rotation about x is:   
 
 y  =
 
    1.    0.    6.  
    0.    1.    8.  
    0.    0.    1.  
 
 z  =
 
    1.    0.  - 6.  
    0.    1.  - 8.  
    0.    0.    1.  
 
 a  =
 
    0.5        - 0.8660254    0.  
    0.8660254    0.5          0.  
    0.           0.           1.  
 
 R  =
 
    0.5        - 0.8660254    9.9282032  
    0.8660254    0.5        - 1.1961524  
    0.           0.           1.         
 
 
    0.5        - 0.8660254    9.9282032  
    0.8660254    0.5        - 1.1961524  
    0.           0.           1.         
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.8.23/2_8_23.sce #
 
 the given matrix is:   
 
 a  =
 
    4.    5.    9.  - 2.   
    6.    5.    1.    12.  
    3.    4.    8.  - 3.   
 
 
    4.    5.    9.  - 2.   
    6.    5.    1.    12.  
    3.    4.    8.  - 3.   
 
 
 performing row operaions   
 
 a  =
 
    4.    5.     9.    - 2.   
    0.  - 2.5  - 12.5    15.  
    3.    4.     8.    - 3.   
 
 a  =
 
    4.    5.      9.    - 2.   
    0.  - 2.5   - 12.5    15.  
    0.    0.25    1.25  - 1.5  
 
 
    4.    5.      9.    - 2.   
    0.  - 2.5   - 12.5    15.  
    0.    0.25    1.25  - 1.5  
 
 a  =
 
    4.    5.     9.    - 2.   
    0.  - 2.5  - 12.5    15.  
    0.    0.     0.      0.   
 
 
    4.    5.     9.    - 2.   
    0.  - 2.5  - 12.5    15.  
    0.    0.     0.      0.   
 
 a  =
 
    1.    1.25    2.25  - 0.5  
    0.  - 2.5   - 12.5    15.  
    0.    0.      0.      0.   
 
 a  =
 
    1.    1.25    2.25  - 0.5  
    0.    1.      5.    - 6.   
    0.    0.      0.      0.   
 
 
    1.    1.25    2.25  - 0.5  
    0.    1.      5.    - 6.   
    0.    0.      0.      0.   
 
 
 column   
 
    1.  
 
 is a pivot column   
 
 column   
 
    2.  
 
 is a pivot column   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.8.25/2_8_25.sce #
 
 the given matrix is:   
 
 a  =
 
    1.    4.    8.  - 3.  - 7.  
  - 1.    2.    7.    3.    4.  
  - 2.    2.    9.    5.    5.  
    3.    6.    9.  - 5.  - 2.  
 
 
    1.    4.    8.  - 3.  - 7.  
  - 1.    2.    7.    3.    4.  
  - 2.    2.    9.    5.    5.  
    3.    6.    9.  - 5.  - 2.  
 
 
 performing row operations   
 
 a  =
 
    1.    4.    8.   - 3.  - 7.  
    0.    6.    15.    0.  - 3.  
  - 2.    2.    9.     5.    5.  
    3.    6.    9.   - 5.  - 2.  
 
 a  =
 
    1.    4.     8.   - 3.  - 7.  
    0.    6.     15.    0.  - 3.  
    0.    10.    25.  - 1.  - 9.  
    3.    6.     9.   - 5.  - 2.  
 
 a  =
 
    1.    4.     8.   - 3.  - 7.   
    0.    6.     15.    0.  - 3.   
    0.    10.    25.  - 1.  - 9.   
    0.  - 6.   - 15.    4.    19.  
 
 
    1.    4.     8.   - 3.  - 7.   
    0.    6.     15.    0.  - 3.   
    0.    10.    25.  - 1.  - 9.   
    0.  - 6.   - 15.    4.    19.  
 
 a  =
 
    1.    4.    8.   - 3.  - 7.   
    0.    6.    15.    0.  - 3.   
    0.    0.    0.   - 1.  - 4.   
    0.  - 6.  - 15.    4.    19.  
 
 a  =
 
    1.    4.    8.   - 3.  - 7.   
    0.    6.    15.    0.  - 3.   
    0.    0.    0.   - 1.  - 4.   
    0.    0.    0.     4.    16.  
 
 
    1.    4.    8.   - 3.  - 7.   
    0.    6.    15.    0.  - 3.   
    0.    0.    0.   - 1.  - 4.   
    0.    0.    0.     4.    16.  
 
 a  =
 
    1.    4.    8.   - 3.  - 7.  
    0.    6.    15.    0.  - 3.  
    0.    0.    0.   - 1.  - 4.  
    0.    0.    0.     0.    0.  
 
 
    1.    4.    8.   - 3.  - 7.  
    0.    6.    15.    0.  - 3.  
    0.    0.    0.   - 1.  - 4.  
    0.    0.    0.     0.    0.  
 
 
 column   
 
    1.  
 
 is a pivot column   
 
 column   
 
    2.  
 
 is a pivot column   
 
 column   
 
    4.  
 
 is a pivot column   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.8.7/2_8_7.sce #
 
 the given matrix is:   
 
 A  =
 
    2.  - 3.  - 4.  
  - 8.    8.    6.  
    6.  - 7.  - 7.  
 
 
 A=   
 
    2.  - 3.  - 4.  
  - 8.    8.    6.  
    6.  - 7.  - 7.  
 
 
 the given vector is:   
 
 p  =
 
    6.   
  - 10.  
    11.  
 
 
 p=   
 
    6.   
  - 10.  
    11.  
 
 
 combining A and p   
 
 b  =
 
    2.  - 3.  - 4.    6.   
  - 8.    8.    6.  - 10.  
    6.  - 7.  - 7.    11.  
 
 
    2.  - 3.  - 4.    6.   
  - 8.    8.    6.  - 10.  
    6.  - 7.  - 7.    11.  
 
 
 performing row operations   
 
 b  =
 
    2.  - 3.  - 4.     6.   
    0.  - 4.  - 10.    14.  
    6.  - 7.  - 7.     11.  
 
 b  =
 
    2.  - 3.  - 4.     6.   
    0.  - 4.  - 10.    14.  
    0.    2.    5.   - 7.   
 
 
    2.  - 3.  - 4.     6.   
    0.  - 4.  - 10.    14.  
    0.    2.    5.   - 7.   
 
 b  =
 
    2.  - 3.  - 4.     6.   
    0.  - 4.  - 10.    14.  
    0.    0.    0.     0.   
 
 
    2.  - 3.  - 4.     6.   
    0.  - 4.  - 10.    14.  
    0.    0.    0.     0.   
 
 
 p lies in column space of A   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH2/EX2.9.13/2_9_13.sce #
 
 the given matrix is:   
 
 a  =
 
    1.  - 3.     2.  - 4.  
  - 3.    9.   - 1.    5.  
    2.  - 6.     4.  - 3.  
  - 4.    12.    2.    7.  
 
 
    1.  - 3.     2.  - 4.  
  - 3.    9.   - 1.    5.  
    2.  - 6.     4.  - 3.  
  - 4.    12.    2.    7.  
 
 
 performing row operations   
 
 a  =
 
    1.  - 3.     2.  - 4.  
    0.    0.     5.  - 7.  
    2.  - 6.     4.  - 3.  
  - 4.    12.    2.    7.  
 
 a  =
 
    1.  - 3.     2.  - 4.  
    0.    0.     5.  - 7.  
    0.    0.     0.    5.  
  - 4.    12.    2.    7.  
 
 a  =
 
    1.  - 3.    2.   - 4.  
    0.    0.    5.   - 7.  
    0.    0.    0.     5.  
    0.    0.    10.  - 9.  
 
 
    1.  - 3.    2.   - 4.  
    0.    0.    5.   - 7.  
    0.    0.    0.     5.  
    0.    0.    10.  - 9.  
 
 a  =
 
    1.  - 3.    2.  - 4.  
    0.    0.    5.  - 7.  
    0.    0.    0.    5.  
    0.    0.    0.    5.  
 
 
    1.  - 3.    2.  - 4.  
    0.    0.    5.  - 7.  
    0.    0.    0.    5.  
    0.    0.    0.    5.  
 
 a  =
 
    1.  - 3.    2.  - 4.  
    0.    0.    5.  - 7.  
    0.    0.    0.    5.  
    0.    0.    0.    0.  
 
 
    1.  - 3.    2.  - 4.  
    0.    0.    5.  - 7.  
    0.    0.    0.    5.  
    0.    0.    0.    0.  
 
 k  =
 
    0.  
 
 k  =
 
    1.  
 k  =
 
    2.  
 k  =
 
    3.  
 
 
 dimension of the matrix=   
 
    3.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.5.3/problem3.sce #
 
 to find the dimension of subspace H, which is the set of linear combination of 
       vectors v1 v2 and v3                                                     
 
 v1  =
 
    0.  
    1.  
    0.  
    1.  
 
 v2  =
 
    0.  
  - 1.  
    1.  
    2.  
 
 v3  =
 
    2.  
    0.  
  - 3.  
    0.  
 
 
 v1=   
 
    0.  
    1.  
    0.  
    1.  
 
 v2=   
 
    0.  
  - 1.  
    1.  
    2.  
 
 v3=   
 
    2.  
    0.  
  - 3.  
    0.  
 
 
 Clearly, v1 is not equal to zero   
 
 
 and v2 is not a multiple of v1 as third element of v1 is zero whereas that of  
      v2 is 1.                                                                  
 
 
 Also, v3 is not a linear combination of v1 and v2 as the first element of v1 a 
      nd v2 is zero but that of v3 is 2                                         
 
 
 Hence, v1 v2 and v3 are linearly independent and dim(H)=3   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.1.13/3_1_13.sce #
 
 the given matrix is:   
 
 A  =
 
    4.    0.  - 7.    3.  - 5.  
    0.    0.    2.    0.    0.  
    7.    3.  - 6.    4.  - 8.  
    5.    0.    5.    2.  - 3.  
    0.    0.    9.  - 1.    2.  
 
 
 A=   
 
    4.    0.  - 7.    3.  - 5.  
    0.    0.    2.    0.    0.  
    7.    3.  - 6.    4.  - 8.  
    5.    0.    5.    2.  - 3.  
    0.    0.    9.  - 1.    2.  
 
 P  =
 
    4.    0.  - 7.    3.  - 5.  
    0.    0.    2.    0.    0.  
    7.    3.  - 6.    4.  - 8.  
    5.    0.    5.    2.  - 3.  
    0.    0.    9.  - 1.    2.  
 
 
 since row 2 has maximum zeros, using row 2 for cofactor expression   
 
 A  =
 
    4.    0.  - 7.    3.  - 5.  
    7.    3.  - 6.    4.  - 8.  
    5.    0.    5.    2.  - 3.  
    0.    0.    9.  - 1.    2.  
 
 A  =
 
    4.    0.    3.  - 5.  
    7.    3.    4.  - 8.  
    5.    0.    2.  - 3.  
    0.    0.  - 1.    2.  
 
 
 deleting second row and third column from A, we get   
 
 
    4.    0.    3.  - 5.  
    7.    3.    4.  - 8.  
    5.    0.    2.  - 3.  
    0.    0.  - 1.    2.  
 
 
 det(A)=-2 X   
 
 det   
 
    4.    0.    3.  - 5.  
    7.    3.    4.  - 8.  
    5.    0.    2.  - 3.  
    0.    0.  - 1.    2.  
 
 
 for the 4X4 matrix obtained, using column 2 for cofactor exansion   
 
 
 deleting second column and row from the 4X4 matrix   
 
 A  =
 
    4.    0.    3.  - 5.  
    5.    0.    2.  - 3.  
    0.    0.  - 1.    2.  
 
 A  =
 
    4.    3.  - 5.  
    5.    2.  - 3.  
    0.  - 1.    2.  
 
 
    4.    3.  - 5.  
    5.    2.  - 3.  
    0.  - 1.    2.  
 
 
 det(A)=-2 X 3 X   
 
 det   
 
    4.    3.  - 5.  
    5.    2.  - 3.  
    0.  - 1.    2.  
 
 
 =   
 
 -6 X [4 X (4-3)-5 X (6-5)]   
 
 
 =   
 
    6.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.1.19/3_1_19.sce #
 
 the given matrix is:   
 
 
 A=   
 
 
 a  b   
 
 
 c  d   
 
 
 det(A)=ad-bc   
 
 
 interchanging the rows of A, we get   
 
 
 B=   
 
 
 c  d   
 
 
 a  b   
 
 
 det(B)=bc-ad   
 
 
 =   
 
 -(ad-bc)   
 
 
 =   
 
 -det(A)   
 
 
 interchanging 2 rows reverses the sign of the determinant   
 
 
 at least for the 2X2 case   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.1.1/3_1_1.sce #
 
 the given matrix is:   
 
 A  =
 
    3.    0.    4.  
    2.    3.    2.  
    0.    5.  - 1.  
 
 
    3.    0.    4.  
    2.    3.    2.  
    0.    5.  - 1.  
 
 
 calculating det(A) using cofactor expression along first row   
 
 
 det(A)=3 X (-1 X 3-5 X 2)+4 X (2 X 5-3 X 0)   
 
 
 =   
 
    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.1.37/3_1_37.sce #
 A  =
 
    3.    1.  
    4.    2.  
 
 
 the given matrix is:   
 
 
    3.    1.  
    4.    2.  
 
 
 det(A)=   
 
    2.  
 
 
 5 X A =    
 
 
    15.    5.   
    20.    10.  
 
 
 det(5*A)=   
 
    50.  
 
 
 thus, det(5A) is not equal to 5Xdet(A)   
 
 
 infact, the relation between det(rA) and det(A) for a nxn matrix is:   
 
 
 det(rA)=(r^n)*det(A)   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.1.7/3_1_7.sce #
 
 given matrix is:   
 
 A  =
 
    4.    3.    0.  
    6.    5.    2.  
    9.    7.    3.  
 
 
    4.    3.    0.  
    6.    5.    2.  
    9.    7.    3.  
 
 
 calculating det(A) using cofactor expression along first row   
 
 
 det(A)=4 X (5 X 3-7 X 2)-3 X (6 X 3-9 X 2)   
 
 
 =   
 
    4.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.2.13/3_2_13.sce #
 
 the given matrix is:   
 
 a  =
 
    2.    5.    4.    1.  
    4.    7.    6.    2.  
    6.  - 2.  - 4.    0.  
  - 6.    7.    7.    0.  
 
 
 A=   
 
    2.    5.    4.    1.  
    4.    7.    6.    2.  
    6.  - 2.  - 4.    0.  
  - 6.    7.    7.    0.  
 
 
 performing row operations   
 
 a  =
 
    2.    5.    4.    1.  
    0.  - 3.  - 2.    0.  
    6.  - 2.  - 4.    0.  
  - 6.    7.    7.    0.  
 
 
    2.    5.    4.    1.  
    0.  - 3.  - 2.    0.  
    6.  - 2.  - 4.    0.  
  - 6.    7.    7.    0.  
 
 
 using cofactor expansion about fourth column   
 
 a  =
 
    0.  - 3.  - 2.    0.  
    6.  - 2.  - 4.    0.  
  - 6.    7.    7.    0.  
 
 a  =
 
    0.  - 3.  - 2.  
    6.  - 2.  - 4.  
  - 6.    7.    7.  
 
 
 det(A)= -1 X   
 
 det   
 
    0.  - 3.  - 2.  
    6.  - 2.  - 4.  
  - 6.    7.    7.  
 
 
 performing row operations   
 
 a  =
 
    0.  - 3.  - 2.  
    6.  - 2.  - 4.  
    0.    5.    3.  
 
 
    0.  - 3.  - 2.  
    6.  - 2.  - 4.  
    0.    5.    3.  
 
 
 using cofactor expansion about first column   
 
 a  =
 
    0.  - 3.  - 2.  
    0.    5.    3.  
 
 a  =
 
  - 3.  - 2.  
    5.    3.  
 
 
 det(A)= -1 X -6 X   
 
 det   
 
  - 3.  - 2.  
    5.    3.  
 
 
 =   
 
    6.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.2.19/3_2_19.sce #
 
 the given matrix is:   
 
 
 A=   
 
 
  a       b       c   
 
 
 2d+a    2e+b    2f+c   
 
 
  g       h       i   
 
 
 B=   
 
 
 a  b  c   
 
 
 d  e  f   
 
 
 g  h  i   
 
 
 given, det(B)=7   
 
 
 performing row operations on A   
 
 
 R2=R2-R1   
 
 
 A=   
 
 
 a   b   c   
 
 
 2d  2e  2f   
 
 
 g   h   i   
 
 
 factoring 2 out of row 2   
 
 
 A=   
 
 
 2 X   
 
 
 a  b  c   
 
 
 d  e  f   
 
 
 g  h  i   
 
 
 therefore, det(A)=2 X det(B)   
 
 
 =2 X 7   
 
 
 = 14   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.2.25/3_2_25.sce #
 
 the given vectors are:   
 
 v1  =
 
    7.  
  - 4.  
  - 6.  
 
 v2  =
 
  - 8.  
    5.  
    7.  
 
 v3  =
 
    7.  
    0.  
  - 5.  
 
 
 v1=   
 
    7.  
  - 4.  
  - 6.  
 
 v2=   
 
  - 8.  
    5.  
    7.  
 
 v3=   
 
    7.  
    0.  
  - 5.  
 
 
 combining them as a matrix   
 
 a  =
 
    7.  - 8.    7.  
  - 4.    5.    0.  
  - 6.    7.  - 5.  
 
 
 A=   
 
    7.  - 8.    7.  
  - 4.    5.    0.  
  - 6.    7.  - 5.  
 
 
 if det(A) is not equal to zero, then v1 v2 and v3 are linearly independent   
 
 
 expanding about third column   
 
 
 det(A)=7 X (-28+30) - 5 X (35-32)   
 
 
 =   
 
  - 1.  
 
 
 hence, v1 v2 and v3 are linearly independent   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.2.7/3_2_7.sce #
 
 the given matrix is:   
 
 A  =
 
    1.    3.    0.    2.  
  - 2.  - 5.    7.    4.  
    3.    5.    2.    1.  
    1.  - 1.    2.  - 3.  
 
 
 A=   
 
    1.    3.    0.    2.  
  - 2.  - 5.    7.    4.  
    3.    5.    2.    1.  
    1.  - 1.    2.  - 3.  
 
 
 performing row operations   
 
 A  =
 
    1.    3.    0.    2.  
    0.    1.    7.    8.  
    3.    5.    2.    1.  
    1.  - 1.    2.  - 3.  
 
 A  =
 
    1.    3.    0.    2.  
    0.    1.    7.    8.  
    0.  - 4.    2.  - 5.  
    1.  - 1.    2.  - 3.  
 
 A  =
 
    1.    3.    0.    2.  
    0.    1.    7.    8.  
    0.  - 4.    2.  - 5.  
    0.  - 4.    2.  - 5.  
 
 
    1.    3.    0.    2.  
    0.    1.    7.    8.  
    0.  - 4.    2.  - 5.  
    0.  - 4.    2.  - 5.  
 
 A  =
 
    1.    3.    0.     2.   
    0.    1.    7.     8.   
    0.    0.    30.    27.  
    0.  - 4.    2.   - 5.   
 
 A  =
 
    1.    3.    0.     2.   
    0.    1.    7.     8.   
    0.    0.    30.    27.  
    0.    0.    30.    27.  
 
 
    1.    3.    0.     2.   
    0.    1.    7.     8.   
    0.    0.    30.    27.  
    0.    0.    30.    27.  
 
 A  =
 
    1.    3.    0.     2.   
    0.    1.    7.     8.   
    0.    0.    30.    27.  
    0.    0.    0.     0.   
 
 
    1.    3.    0.     2.   
    0.    1.    7.     8.   
    0.    0.    30.    27.  
    0.    0.    0.     0.   
 
 
 det(A) is the product of diagonal entries   
 
 
 det(A)=   
 
    0.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.3.13/3_3_13.sce #
 
 the given matrix is:   
 
 a  =
 
    3.    5.    4.  
    1.    0.    1.  
    2.    1.    1.  
 
 
 A=   
 
    3.    5.    4.  
    1.    0.    1.  
    2.    1.    1.  
 
 
 the cofactors are:   
 
 C11  =
 
  - 1.  
 
 
 C11=   
 
  - 1.  
 
 C12  =
 
    1.  
 
 
 C12=   
 
    1.  
 
 C13  =
 
    1.  
 
 
 C13=   
 
    1.  
 
 C21  =
 
  - 1.  
 
 
 C21=   
 
  - 1.  
 
 C22  =
 
  - 5.  
 
 
 C22=   
 
  - 5.  
 
 C23  =
 
    7.  
 
 
 C23=   
 
    7.  
 
 C31  =
 
    5.  
 
 
 C31=   
 
    5.  
 
 C32  =
 
    1.  
 
 
 C32=   
 
    1.  
 
 C33  =
 
  - 5.  
 
 
 C33=   
 
  - 5.  
 
 B  =
 
  - 1.  - 1.    5.  
    1.  - 5.    1.  
    1.    7.  - 5.  
 
 
 adj(A)=   
 
 
  - 1.  - 1.    5.  
    1.  - 5.    1.  
    1.    7.  - 5.  
 
 C  =
 
  - 0.1666667  - 0.1666667    0.8333333  
    0.1666667  - 0.8333333    0.1666667  
    0.1666667    1.1666667  - 0.8333333  
 
 
 inv(A)=   
 
 
  - 0.1666667  - 0.1666667    0.8333333  
    0.1666667  - 0.8333333    0.1666667  
    0.1666667    1.1666667  - 0.8333333  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.3.19/3_3_19.sce #
 
 the points forming the parrallelogram are   
 
 
 (0,0),(5,2),(6,4),(11,6)   
 
 
 using the vertices adjacent to origin to form a matrix   
 
 A  =
 
    5.    6.  
    2.    4.  
 
 
 A=   
 
    5.    6.  
    2.    4.  
 
 
 Area of parallelogram = det(A)   
 
 
 =   
 
    8.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH3/EX3.3.1/3_3_1.sce #
 
 the co-efficient matrix is:   
 
 a  =
 
    5.    7.  
    2.    4.  
 
 
 A=   
 
    5.    7.  
    2.    4.  
 
 
 the RHS is:   
 
 b  =
 
    3.  
    1.  
 
 
    3.  
    1.  
 
 
 applying cramers rule   
 
 
 replacing first column of matrix A by b   
 
 A1  =
 
    3.    7.  
    1.    4.  
 
 
 A1=   
 
    3.    7.  
    1.    4.  
 
 
 replacing second column of matrix A by b   
 
 A2  =
 
    5.    3.  
    2.    1.  
 
 
 A2=   
 
    5.    3.  
    2.    1.  
 
 
 x1=det(A1)/det(A)   
 
 
 =   
 
    0.8333333  
 
 
 x2=det(A2)/det(A)   
 
 
 =   
 
  - 0.1666667  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.1.13/4_1_13.sce #
 
 the given vectors are:   
 
 v1  =
 
    1.  
    0.  
  - 1.  
 
 
 v1=   
 
    1.  
    0.  
  - 1.  
 
 v2  =
 
    2.  
    1.  
    3.  
 
 
 v2=   
 
    2.  
    1.  
    3.  
 
 v3  =
 
    4.  
    2.  
    6.  
 
 
 v3=   
 
    4.  
    2.  
    6.  
 
 w  =
 
    3.  
    1.  
    2.  
 
 
 w=   
 
    3.  
    1.  
    2.  
 
 
 It is  that w is not one of the three vectors in v1,v2 and v3   
 
 
 The span of v1,v2 and v3 contains infinitely many vectors.   
 
 
 To check if w is in the subspace of v1,v2 and v3,   
 
 
 we form an augmented matrix.   
 
 a  =
 
    1.    2.    4.    3.  
    0.    1.    2.    1.  
  - 1.    3.    6.    2.  
 
 
    1.    2.    4.    3.  
    0.    1.    2.    1.  
  - 1.    3.    6.    2.  
 
 
 performing row operations   
 
 
 R3=R3+R1   
 
 a  =
 
    1.    2.    4.     3.  
    0.    1.    2.     1.  
    0.    5.    10.    5.  
 
 
    1.    2.    4.     3.  
    0.    1.    2.     1.  
    0.    5.    10.    5.  
 
 
 R3=R3-5xR2   
 
 a  =
 
    1.    2.    4.    3.  
    0.    1.    2.    1.  
    0.    0.    0.    0.  
 
 
    1.    2.    4.    3.  
    0.    1.    2.    1.  
    0.    0.    0.    0.  
 
 
 there is no pivot in the augmented column,   
 
 
 hence the vector equation is consistent and w is in span{v1 v2 v3}.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.2.1/4_2_1.sce #
 
 the given matrix is:   
 
 a  =
 
    3.  - 5.  - 3.  
    6.  - 2.    0.  
  - 8.    4.    1.  
 
 
 A=   
 
    3.  - 5.  - 3.  
    6.  - 2.    0.  
  - 8.    4.    1.  
 
 
 the vector x is:   
 
 x  =
 
    1.  
    3.  
  - 4.  
 
 
 x=   
 
    1.  
    3.  
  - 4.  
 
 
 To check if x is in nullspace of A   
 
 
 Ax=   
 
 
 =   
 
    0.  
    0.  
    0.  
 
 
 hence, x is in the null space of A   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.3.13/4_3_13.sce #
 
 the given matrix is:   
 
 a  =
 
    1.    0.    6.    5.  
    0.    2.    5.    3.  
    0.    0.    0.    0.  
 
 p  =
 
    1.    0.    6.    5.  
    0.    2.    5.    3.  
    0.    0.    0.    0.  
 
 
 A=   
 
    1.    0.    6.    5.  
    0.    2.    5.    3.  
    0.    0.    0.    0.  
 
 
 Reducing A to echelon form   
 
 
 R2=R2/2   
 
 a  =
 
    1.    0.    6.     5.   
    0.    1.    2.5    1.5  
    0.    0.    0.     0.   
 
 
    1.    0.    6.     5.   
    0.    1.    2.5    1.5  
    0.    0.    0.     0.   
 
 
 the pivot columns are column 1 and 2 of A   
 
 
 hence column space of A is:   
 
 
 span   
 
 
    0.  
    1.  
    0.  
 
 and   
 
    1.  
    0.  
    0.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.4.27/4_4_27.sce #
 
 to check if vectors v1 v2 and v3 are linearly independent   
 
 v1  =
 
    1.  
    0.  
    0.  
    1.  
 
 v2  =
 
    3.  
    1.  
  - 2.  
    0.  
 
 v3  =
 
    0.  
  - 1.  
    3.  
  - 1.  
 
 
 v1=   
 
    1.  
    0.  
    0.  
    1.  
 
 v2=   
 
    3.  
    1.  
  - 2.  
    0.  
 
 v3=   
 
    0.  
  - 1.  
    3.  
  - 1.  
 
 
 forming an augmented matrix   
 
 a  =
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.  - 2.    3.    0.  
    1.    0.  - 1.    0.  
 
 
 A=   
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.  - 2.    3.    0.  
    1.    0.  - 1.    0.  
 
 
 performing row operations   
 
 a  =
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.  - 2.    3.    0.  
    0.  - 3.  - 1.    0.  
 
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.  - 2.    3.    0.  
    0.  - 3.  - 1.    0.  
 
 a  =
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.    0.    1.    0.  
    0.  - 3.  - 1.    0.  
 
 a  =
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.    0.    1.    0.  
    0.    0.  - 4.    0.  
 
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.    0.    1.    0.  
    0.    0.  - 4.    0.  
 
 a  =
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.    0.    1.    0.  
    0.    0.    0.    0.  
 
 
    1.    3.    0.    0.  
    0.    1.  - 1.    0.  
    0.    0.    1.    0.  
    0.    0.    0.    0.  
 
 
 since the vector equation has only the trivial solution   
 
 
 vectors v1 v2 and v3 are linearly independent   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.4.31a/4_4_31_parta.sce #
 
 to check if the polynomials span R3   
 
 
 placing the coordinate vectors of the polynomial into the columns of a matrix  
 
 a  =
 
    1.  - 3.  - 4.    1.  
  - 3.    5.    5.    0.  
    5.  - 7.  - 6.    1.  
 
 
 A=   
 
    1.  - 3.  - 4.    1.  
  - 3.    5.    5.    0.  
    5.  - 7.  - 6.    1.  
 
 
 performing row operations   
 
 a  =
 
    1.  - 3.  - 4.    1.  
    0.  - 4.  - 7.    3.  
    5.  - 7.  - 6.    1.  
 
 a  =
 
    1.  - 3.  - 4.     1.  
    0.  - 4.  - 7.     3.  
    0.    8.    14.  - 4.  
 
 
    1.  - 3.  - 4.     1.  
    0.  - 4.  - 7.     3.  
    0.    8.    14.  - 4.  
 
 a  =
 
    1.  - 3.  - 4.    1.  
    0.  - 4.  - 7.    3.  
    0.    0.    0.    2.  
 
 
    1.  - 3.  - 4.    1.  
    0.  - 4.  - 7.    3.  
    0.    0.    0.    2.  
 
 
 the four vectors DO NOT span R3 as there is no pivot in row 3   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.4.31b/4_4_31_partb.sce #
 
 to check if the polynomials span R3   
 
 
 placing the coordinate vectors of the polynomial into the columns of a matrix  
 
 a  =
 
    0.    1.  - 3.    2.  
    5.  - 8.    4.  - 3.  
    1.  - 2.    2.    0.  
 
 
 A=   
 
    0.    1.  - 3.    2.  
    5.  - 8.    4.  - 3.  
    1.  - 2.    2.    0.  
 
 
 performing row operations   
 
 a  =
 
    1.  - 2.    2.    0.  
    5.  - 8.    4.  - 3.  
    0.    1.  - 3.    2.  
 
 
    1.  - 2.    2.    0.  
    5.  - 8.    4.  - 3.  
    0.    1.  - 3.    2.  
 
 a  =
 
    1.  - 2.    2.    0.  
    0.    2.  - 6.  - 3.  
    0.    1.  - 3.    2.  
 
 
    1.  - 2.    2.    0.  
    0.    2.  - 6.  - 3.  
    0.    1.  - 3.    2.  
 
 a  =
 
    1.  - 2.    2.    0.   
    0.    2.  - 6.  - 3.   
    0.    0.    0.    3.5  
 
 
    1.  - 2.    2.    0.   
    0.    2.  - 6.  - 3.   
    0.    0.    0.    3.5  
 
 
 the four vectors SPAN R3 as there is a pivot in each row   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH4/EX4.4.7/4_4_7.sce #
 
 vector x=   
 
 x  =
 
    8.  
  - 9.  
    6.  
 
 
    8.  
  - 9.  
    6.  
 
 
 the given basis is:   
 
 b1  =
 
    1.  
  - 1.  
  - 3.  
 
 b2  =
 
  - 3.  
    4.  
    9.  
 
 b3  =
 
    2.  
  - 2.  
    4.  
 
 
 b1=   
 
    1.  
  - 1.  
  - 3.  
 
 
 b2=   
 
  - 3.  
    4.  
    9.  
 
 
 b3=   
 
    2.  
  - 2.  
    4.  
 
 
 to solve the vector equation   
 
 
 an augmented matrix is formed   
 
 a  =
 
    1.  - 3.    2.    8.  
  - 1.    4.  - 2.  - 9.  
  - 3.    9.    4.    6.  
 
 
 A=   
 
    1.  - 3.    2.    8.  
  - 1.    4.  - 2.  - 9.  
  - 3.    9.    4.    6.  
 
 
 performing row operations   
 
 a  =
 
    1.  - 3.    2.    8.  
    0.    1.    0.  - 1.  
  - 3.    9.    4.    6.  
 
 a  =
 
    1.  - 3.    2.     8.   
    0.    1.    0.   - 1.   
    0.    0.    10.    30.  
 
 
    1.  - 3.    2.     8.   
    0.    1.    0.   - 1.   
    0.    0.    10.    30.  
 
 a  =
 
    1.  - 3.    2.    8.  
    0.    1.    0.  - 1.  
    0.    0.    1.    3.  
 
 a  =
 
    1.  - 3.    0.    2.  
    0.    1.    0.  - 1.  
    0.    0.    1.    3.  
 
 
    1.  - 3.    0.    2.  
    0.    1.    0.  - 1.  
    0.    0.    1.    3.  
 
 a  =
 
    1.    0.    0.  - 1.  
    0.    1.    0.  - 1.  
    0.    0.    1.    3.  
 
 
    1.    0.    0.  - 1.  
    0.    1.    0.  - 1.  
    0.    0.    1.    3.  
 
 
 Xb=   
 
 
  - 1.  
  - 1.  
    3.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.1.13/5_1_13.sce #
 
 To find a basis for the eigenspace   
 
 
 Matrix A=   
 
 a  =
 
    4.    0.    1.  
  - 2.    1.    0.  
  - 2.    0.    1.  
 
 
    4.    0.    1.  
  - 2.    1.    0.  
  - 2.    0.    1.  
 
 
 for lambda=1   
 
 
 A-1I=   
 
 b  =
 
    3.    0.    1.  
  - 2.    0.    0.  
  - 2.    0.    0.  
 
 
    3.    0.    1.  
  - 2.    0.    0.  
  - 2.    0.    0.  
 
 
 solving (A-I)x=0, we get   
 
 
 -2*x1=0 and 3*x1+x3=0   
 
 
 therefore, x1=x3=0   
 
 
 which leaves x2 as a free variable   
 
 
 Hence a basis for the eigen space is:   
 
 
    0.  
    1.  
    0.  
 
 
 for lambda=2   
 
 
 A-2I=   
 
 b  =
 
    2.    0.    1.  
  - 2.  - 1.    0.  
  - 2.    0.  - 1.  
 
 
    2.    0.    1.  
  - 2.  - 1.    0.  
  - 2.    0.  - 1.  
 
 
 performing row operations on the augmented matrix   
 
 c  =
 
    2.    0.    1.    0.  
  - 2.  - 1.    0.    0.  
  - 2.    0.  - 1.    0.  
 
 
    2.    0.    1.    0.  
  - 2.  - 1.    0.    0.  
  - 2.    0.  - 1.    0.  
 
 c  =
 
    2.    0.    1.    0.  
    0.  - 1.    1.    0.  
  - 2.    0.  - 1.    0.  
 
 c  =
 
    2.    0.    1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 
    2.    0.    1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 c  =
 
  - 2.    0.  - 1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 
  - 2.    0.  - 1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 
 We can see that x3 is a free variable   
 
 
 x2=x3 and x1=-.05*x3   
 
 
 Hence, a basis for the eigenspace is:   
 
 
  - 0.5  
    1.   
    1.   
 
 
 for lambda=3   
 
 
 A-3I=   
 
 b  =
 
    1.    0.    1.  
  - 2.  - 2.    0.  
  - 2.    0.  - 2.  
 
 
    1.    0.    1.  
  - 2.  - 2.    0.  
  - 2.    0.  - 2.  
 
 
 performing row operations on the augmented matrix   
 
 c  =
 
    1.    0.    1.    0.  
  - 2.  - 2.    0.    0.  
  - 2.    0.  - 2.    0.  
 
 
    1.    0.    1.    0.  
  - 2.  - 2.    0.    0.  
  - 2.    0.  - 2.    0.  
 
 c  =
 
    1.    0.    1.    0.  
    0.  - 2.    2.    0.  
  - 2.    0.  - 2.    0.  
 
 c  =
 
    1.    0.    1.    0.  
    0.  - 2.    2.    0.  
    0.    0.    0.    0.  
 
 
    1.    0.    1.    0.  
    0.  - 2.    2.    0.  
    0.    0.    0.    0.  
 
 c  =
 
    1.    0.    1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 
    1.    0.    1.    0.  
    0.  - 1.    1.    0.  
    0.    0.    0.    0.  
 
 
 Again x3 is a free variable   
 
 
 x1=-x3 and x2=x3   
 
 
 Hence, a basis for the eigenspace is:   
 
 
  - 1.  
    1.  
    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.1.19/5_1_19.sce #
 
 The given matrix is:   
 
 a  =
 
    1.    1.    1.  
    2.    2.    2.  
    3.    3.    3.  
 
 
 A=   
 
    1.    1.    1.  
    2.    2.    2.  
    3.    3.    3.  
 
 
 A is not invertible because its columns are linearly dependent.   
 
 
 Hence, 0 is an eigenvalue of matrix A.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.1.1/5_1_1.sce #
 
 to check if 2 is an eigenvalue of matrix A   
 
 a  =
 
    3.    2.  
    3.    8.  
 
 
 A=   
 
    3.    2.  
    3.    8.  
 
 
 A-2I=   
 
 b  =
 
    1.    2.  
    3.    6.  
 
 
    1.    2.  
    3.    6.  
 
 
 The columns of A are ly independent,   
 
 
 hence (A-2I)x=0 has a non trivial solution and 2 is an eigenvalue of matrix A  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.1.7/5_1_7.sce #
 
 To check if 4 is an eigenvalue of matrix A   
 
 a  =
 
    3.    0.  - 1.  
    2.    3.    1.  
  - 3.    4.    5.  
 
 
 A=   
 
    3.    0.  - 1.  
    2.    3.    1.  
  - 3.    4.    5.  
 
 
 Therefore   
 
 
 A-4I=   
 
 
  - 1.    0.  - 1.  
    2.  - 1.    1.  
  - 3.    4.    1.  
 
 b  =
 
  - 1.    0.  - 1.  
    2.  - 1.    1.  
  - 3.    4.    1.  
 
 
 to check the invertibility of A-4I, form an augmented matrix   
 
 c  =
 
  - 1.    0.  - 1.    0.  
    2.  - 1.    1.    0.  
  - 3.    4.    1.    0.  
 
 
  - 1.    0.  - 1.    0.  
    2.  - 1.    1.    0.  
  - 3.    4.    1.    0.  
 
 
 performing row operations   
 
 c  =
 
  - 1.    0.  - 1.    0.  
    0.  - 1.  - 1.    0.  
  - 3.    4.    1.    0.  
 
 c  =
 
  - 1.    0.  - 1.    0.  
    0.  - 1.  - 1.    0.  
    0.    4.    4.    0.  
 
 
  - 1.    0.  - 1.    0.  
    0.  - 1.  - 1.    0.  
    0.    4.    4.    0.  
 
 c  =
 
  - 1.    0.  - 1.    0.  
    0.  - 1.  - 1.    0.  
    0.    0.    0.    0.  
 
 
  - 1.    0.  - 1.    0.  
    0.  - 1.  - 1.    0.  
    0.    0.    0.    0.  
 
 
 We can see that there exists a non trivial solution.   
 
 
 Hence, 4 is an eigenvalue of A.   
 
 
 For the eigenvector, -x1-x3=0 and -x2-x3=0   
 
 
 If x3=1,   
 
 x  =
 
  - 1.  
  - 1.  
    1.  
 
 
 x=   
 
  - 1.  
  - 1.  
    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.2.13/5_2_13.sce #
 
 To find the eigenvalues of the matrix A   
 
 
 A=   
 
 a  =
 
    6.  - 2.    0.  
  - 2.    9.    0.  
    5.    8.    3.  
 
 
    6.  - 2.    0.  
  - 2.    9.    0.  
    5.    8.    3.  
 
 
 Eigenvalues of A are:   
 
 
    3.   
    10.  
    5.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.2.1/5_2_1.sce #
 
 To find the eigenvalue of matrix A   
 
 
 A=   
 
 a  =
 
    2.    7.  
    7.    2.  
 
 
    2.    7.  
    7.    2.  
 
 
 Eigen values of A are:   
 
 
  - 5.  
    9.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.2.25/5_2_25.sce #
 
 Matrix A=   
 
 a  =
 
    0.6    0.3  
    0.4    0.7  
 
 
    0.6    0.3  
    0.4    0.7  
 
 
 Eigenvector v1=   
 
 v1  =
 
    0.4285714  
    0.5714286  
 
 
    0.4285714  
    0.5714286  
 
 
 vector Xo=   
 
 Xo  =
 
    0.5  
    0.5  
 
 
    0.5  
    0.5  
 
 
 Eigenvalues of A are:   
 
 c  =
 
    0.3  
    1.   
 
 
    0.3  
    1.   
 
 
 To verify if v1 is an eigenvector of A:   
 
 
 A*v1=   
 
 
    0.4285714  
    0.5714286  
 
 
 =   
 
 
 1*v1   
 
 
 Hence v1 is an eigenvector of A corresponding to eigenvalue 1.   
 
 
 for lambda=.3   
 
 
 A-.3I=   
 
 b  =
 
    0.3    0.3  
    0.4    0.4  
 
 
    0.3    0.3  
    0.4    0.4  
 
 
 performing row operations on the augmented matrix   
 
 c  =
 
    0.3    0.3    0.  
    0.4    0.4    0.  
 
 
    0.3    0.3    0.  
    0.4    0.4    0.  
 
 c  =
 
    0.3    0.3          0.  
    0.   - 5.551D-17    0.  
 
 
    0.3    0.3          0.  
    0.   - 5.551D-17    0.  
 
 
 hence, x1+x2=0   
 
 
 Eigenvector corresponding to eigenvalue .3 is:   
 
 
  - 1.  
    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.2.7/5_2_7.sce #
 
 To find the eigenvalues of matrix A.   
 
 
 A=   
 
 a  =
 
    5.    3.  
  - 4.    4.  
 
 
    5.    3.  
  - 4.    4.  
 
 
 Eigen values of A are:   
 
 
    4.5 + 3.4278273i  
    4.5 - 3.4278273i  
 
 
 Hence, A has no real eigenvalues.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.3.13/5_3_13.sce #
 
 Given matrix A=   
 
 a  =
 
    2.    2.  - 1.  
    1.    3.  - 1.  
  - 1.  - 2.    2.  
 
 
    2.    2.  - 1.  
    1.    3.  - 1.  
  - 1.  - 2.    2.  
 
 
 Given its eigen values are 5 and 1   
 
 
 for lambda=5   
 
 
 A-5I=   
 
 b  =
 
  - 3.    2.  - 1.  
    1.  - 2.  - 1.  
  - 1.  - 2.  - 3.  
 
 
  - 3.    2.  - 1.  
    1.  - 2.  - 1.  
  - 1.  - 2.  - 3.  
 
 
 performing row operations   
 
 c  =
 
  - 3.    2.  - 1.    0.  
    1.  - 2.  - 1.    0.  
  - 1.  - 2.  - 3.    0.  
 
 
  - 3.    2.  - 1.    0.  
    1.  - 2.  - 1.    0.  
  - 1.  - 2.  - 3.    0.  
 
 c  =
 
    1.  - 2.  - 1.    0.  
  - 3.    2.  - 1.    0.  
  - 1.  - 2.  - 3.    0.  
 
 
    1.  - 2.  - 1.    0.  
  - 3.    2.  - 1.    0.  
  - 1.  - 2.  - 3.    0.  
 
 c  =
 
    1.  - 2.  - 1.    0.  
    0.  - 4.  - 4.    0.  
  - 1.  - 2.  - 3.    0.  
 
 c  =
 
    1.  - 2.  - 1.    0.  
    0.  - 4.  - 4.    0.  
    0.  - 4.  - 4.    0.  
 
 
    1.  - 2.  - 1.    0.  
    0.  - 4.  - 4.    0.  
    0.  - 4.  - 4.    0.  
 
 c  =
 
    1.  - 2.  - 1.    0.  
    0.  - 4.  - 4.    0.  
    0.    0.    0.    0.  
 
 
    1.  - 2.  - 1.    0.  
    0.  - 4.  - 4.    0.  
    0.    0.    0.    0.  
 
 c  =
 
    1.  - 2.  - 1.    0.  
    0.    1.    1.    0.  
    0.    0.    0.    0.  
 
 
    1.  - 2.  - 1.    0.  
    0.    1.    1.    0.  
    0.    0.    0.    0.  
 
 
 With x3 as free variable, x1=-x3 and x2=-x3   
 
 
 Hence, for lambda=5 eigenvector is:   
 
 u1  =
 
  - 1.  
  - 1.  
    1.  
 
 
  - 1.  
  - 1.  
    1.  
 
 
 for lambda=1   
 
 
 A-I=   
 
 b  =
 
    1.    2.  - 1.  
    1.    2.  - 1.  
  - 1.  - 2.    1.  
 
 
    1.    2.  - 1.  
    1.    2.  - 1.  
  - 1.  - 2.    1.  
 
 
 performing row operations   
 
 c  =
 
    1.    2.  - 1.    0.  
    1.    2.  - 1.    0.  
  - 1.  - 2.    1.    0.  
 
 
    1.    2.  - 1.    0.  
    1.    2.  - 1.    0.  
  - 1.  - 2.    1.    0.  
 
 c  =
 
    1.    2.  - 1.    0.  
    0.    0.    0.    0.  
  - 1.  - 2.    1.    0.  
 
 c  =
 
    1.    2.  - 1.    0.  
    0.    0.    0.    0.  
    0.    0.    0.    0.  
 
 
    1.    2.  - 1.    0.  
    0.    0.    0.    0.  
    0.    0.    0.    0.  
 
 
 With x2 and x3 as free variables, eigen vectors corresponding to lambda=1 are  
 
 u2  =
 
  - 2.  
    1.  
    0.  
 
 u3  =
 
    1.  
    0.  
    1.  
 
 
  - 2.  
    1.  
    0.  
 
    1.  
    0.  
    1.  
 
 
 Hence, matrix P=   
 
 
  - 1.  - 2.    1.  
  - 1.    1.    0.  
    1.    0.    1.  
 
 
 and matrix D=   
 
 
    5.    0.    0.  
    0.    1.    0.  
    0.    0.    1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.3.1/5_3_1.sce #
 
 The given eigenvector matrix is:   
 
 p  =
 
    5.    7.  
    2.    3.  
 
 
 P=   
 
    5.    7.  
    2.    3.  
 
 
 The diagonal matrix is:   
 
 d  =
 
    2.    0.  
    0.    1.  
 
 
 D=   
 
    2.    0.  
    0.    1.  
 
 
 Therefore, matrix A=PD(p^-1)   
 
 s  =
 
    3.  - 7.  
  - 2.    5.  
 
 
    16.  - 35.  
    6.   - 13.  
 
 
 Hence, A^4=P(D^4)(P^-1)   
 
 
    226.  - 525.  
    90.   - 209.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.3.7/5_3_7.sce #
 
 the given matrix is:   
 
 a  =
 
    1.    0.  
    6.  - 1.  
 
 
 A=   
 
    1.    0.  
    6.  - 1.  
 
 
 Since A is triangular, eigenvalues are the diagonal entries.   
 
 
 Eigenvalues are:   
 
    1.  
 
  - 1.  
 
 
 for lambda=1   
 
 
 A-1I=   
 
 b  =
 
    0.    0.  
    6.  - 2.  
 
 
    0.    0.  
    6.  - 2.  
 
 
 Hence, x1=(1/3)x2 with x2 as free variable.   
 
 
 Eigenvector corresponding to lambda=1 is:   
 
 u1  =
 
    1.  
    3.  
 
 
    1.  
    3.  
 
 
 for lambda=-1   
 
 
 A-(-1)I=   
 
 b  =
 
    2.    0.  
    6.    0.  
 
 
    2.    0.  
    6.    0.  
 
 
 Hence, x1=0 with x2 as free variable.   
 
 
 Eigenvector corresponding to lambda=-1 is:   
 
 u2  =
 
    0.  
    1.  
 
 
    0.  
    1.  
 
 
 Thus, matrix P=   
 
 
    1.    0.  
    3.    1.  
 
 
 and matrix D=   
 
 
    1.    0.  
    0.  - 1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.4.31/5_4_31.sce #
 
 Given matrix A=   
 
 a  =
 
  - 7.  - 48.  - 16.  
    1.    14.    6.   
  - 3.  - 45.  - 19.  
 
 
  - 7.  - 48.  - 16.  
    1.    14.    6.   
  - 3.  - 45.  - 19.  
 
 
 and matrix P=   
 
 p  =
 
  - 3.  - 2.    3.  
    1.    1.  - 1.  
  - 3.  - 3.    0.  
 
 
  - 3.  - 2.    3.  
    1.    1.  - 1.  
  - 3.  - 3.    0.  
 
 
 Hence, marix D=   
 
 s  =
 
  - 1.         - 3.  - 0.3333333  
    1.           3.    0.         
    5.551D-17  - 1.  - 0.3333333  
 
 
  - 7.         - 2.  - 6.  
    0.         - 4.  - 6.  
    4.441D-16    0.  - 1.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.5.1/5_5_1.sce #
 
 Matrix A=   
 
 a  =
 
    1.  - 2.  
    1.    3.  
 
 
    1.  - 2.  
    1.    3.  
 
 
 Eigen values of A are   
 
 eig  =
 
    2. + i    
    2. - i    
 
 
    2. + i    
    2. - i    
 
 
 for lambda=2+i   
 
 i  =
 
    i    
 
 
 A-(2+i)I=   
 
 b  =
 
  - 1. - i    - 2.        
    1.          1. - i    
 
 
  - 1. - i    - 2.        
    1.          1. - i    
 
 
 With x2 as free variable, x1=-(1-i)x2   
 
 
 Hence, eigenvector corresponding to lambda=2+i is:   
 
 
  - 1. + i    
    1.        
 
 
 for lambda=2-i, eigenvector is:   
 
 
  - 1. - i    
    1.        
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH5/EX5.5.7/5_5_7.sce #
 
 Matrix A=   
 
 a  =
 
    1.7320508  - 1.         
    1.           1.7320508  
 
 
    1.7320508  - 1.         
    1.           1.7320508  
 
 
 Eigenvalues of A are:   
 
 eig  =
 
    1.7320508 + i    
    1.7320508 - i    
 
 
    1.7320508 + i    
    1.7320508 - i    
 
 
 The scale factor associated with the transformation x to Ax is:   
 
 
    2.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.1.13/6_1_13.sce #
 
 Vector x and y are:   
 
 x  =
 
    10.  
  - 3.   
 
 y  =
 
  - 1.  
  - 5.  
 
 
    10.  
  - 3.   
 
  - 1.  
  - 5.  
 
 
 ||x-y||=sqrt(121+4)   
 
 
 =   
 
    11.18034  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.1.1/6_1_1.sce #
 
 Vectors u an v are:   
 
 u  =
 
  - 1.  
    2.  
 
 v  =
 
    4.  
    6.  
 
 
  - 1.  
    2.  
 
    4.  
    6.  
 
 
 Projection of v on u=(u.v)/(v.v)   
 
 a  =
 
    8.  
 
 b  =
 
    5.  
 
 p  =
 
    1.6  
 
 
 =   
 
    1.6  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.1.7/6_1_7.sce #
 
 w=   
 
 w  =
 
    3.  
  - 1.  
  - 5.  
 
 
    3.  
  - 1.  
  - 5.  
 
 
 ||w||=sqrt(9+1+25)   
 
 
    5.9160798  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.2.13/6_2_13.sce #
 
 Vectors y and u are:   
 
 y  =
 
    2.  
    3.  
 
 u  =
 
    4.  
  - 7.  
 
 
    2.  
    3.  
 
    4.  
  - 7.  
 
 
 The orthogonal projection of y on u=((y.u)/(u.u))*u   
 
 a  =
 
  - 13.  
 
 b  =
 
    65.  
 
 c  =
 
  - 0.8  
    1.4  
 
 
 =   
 
  - 0.8  
    1.4  
 
 
 The component of y orthogonal to u is:   
 
 
    2.8  
    1.6  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.2.19/6_2_19.sce #
 
 given vectors u and v are:   
 
 u  =
 
  - 0.6  
    0.8  
 
 v  =
 
    0.8  
    0.6  
 
 
  - 0.6  
    0.8  
 
    0.8  
    0.6  
 
 
 u.v=   
 
 
    0.  
 
 
 Hence, {u v} is an orthogonal set.   
 
 
 ||u||=1 and ||v||=1   
 
 
 Thus, {u v} is an orthonormal set   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.2.1/6_2_1.sce #
 
 To verify if u v and w are orthogonal   
 
 u  =
 
  - 1.  
    4.  
  - 3.  
 
 v  =
 
    5.  
    2.  
    1.  
 
 w  =
 
    3.  
  - 4.  
  - 7.  
 
 
  - 1.  
    4.  
  - 3.  
 
    5.  
    2.  
    1.  
 
    3.  
  - 4.  
  - 7.  
 
 
 u.v=   
 
 
    0.  
 
 
 u.w=   
 
 
    2.  
 
 
 Since u.w is not equal to zero, the set {u v w} is not orthogonal.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.2.7/6_2_7.sce #
 
 vectors u1 u2 and x are:   
 
 u1  =
 
    2.  
  - 3.  
 
 u2  =
 
    6.  
    4.  
 
 x  =
 
    9.  
  - 7.  
 
 
    2.  
  - 3.  
 
    6.  
    4.  
 
    9.  
  - 7.  
 
 
 u1.u2=   
 
 
    0.  
 
 
 u1.u2=0, {u1 u2} is an orthogonal set   
 
 
 Hence {u1 u2} forms a basis of R2   
 
 
 x can be written as: x=a*u1+b*u2   
 
 
 where a=(x.u1)/(u1.u1)   
 
 a1  =
 
    39.  
 
 a2  =
 
    13.  
 
 a  =
 
    3.  
 
 
 =   
 
    3.  
 
 
 and b=(x.u2)/(u2.u2)   
 
 b1  =
 
    26.  
 
 b2  =
 
    52.  
 
 b  =
 
    0.5  
 
 
 =   
 
    0.5  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.3.13/6_3_13.sce #
 
 Given vectors are:   
 
 v1  =
 
    2.  
  - 1.  
  - 3.  
    1.  
 
 v2  =
 
    1.  
    1.  
    0.  
  - 1.  
 
 z  =
 
    3.  
  - 7.  
    2.  
    3.  
 
 
 v1=   
 
    2.  
  - 1.  
  - 3.  
    1.  
 
 v2=   
 
    1.  
    1.  
    0.  
  - 1.  
 
 z=   
 
    3.  
  - 7.  
    2.  
    3.  
 
 a  =
 
    0.  
 
 
 v1.v2=   
 
    0.  
 
 
 v1 and v2 are orthogonal   
 
 
 By best spproximation theorem, st point in span{v1 v2} to z is the orthogonal  
      projection                                                                
 
 
 =((z.v1)/(v1.v1))*v1+((z.v2)/(v2.v2))*v2   
 
 a1  =
 
    10.  
 
 a2  =
 
    15.  
 
 b1  =
 
  - 7.  
 
 b2  =
 
    3.  
 
 
 =   
 
  - 2.3333333  
  - 2.3333333  
    0.         
    2.3333333  
 
 +   
 
    1.3333333  
  - 0.6666667  
  - 2.         
    0.6666667  
 
 
 =   
 
  - 1.  
  - 3.  
  - 2.  
    3.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.3.19/6_3_19.sce #
 
 By orthogonal decomposition theorem,   
 
 
 u3 is the sum of a vector in W=span{u1 u2} and a vector v orthogonal to W   
 
 
 To find v, given u1 and u2   
 
 u1  =
 
    1.  
    1.  
  - 2.  
 
 u2  =
 
    5.  
  - 1.  
    2.  
 
 
 u1=   
 
    1.  
    1.  
  - 2.  
 
 u2=   
 
    5.  
  - 1.  
    2.  
 
 
 Projection of u3 on W   
 
 
 = (-1/3)*u1+(1/15)*u2   
 
 
 =   
 
    0.   
  - 0.4  
    0.8  
 
 
 v= u3-(projection of u3 on W)   
 
 
 =   
 
    0.  
    0.  
    1.  
 
 -   
 
    0.   
  - 0.4  
    0.8  
 
 
 =   
 
    0.   
    0.4  
    0.2  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.3.1/6_3_1.sce #
 
 Given vectors are:   
 
 u1  =
 
    0.  
    1.  
  - 4.  
  - 1.  
 
 u2  =
 
    3.  
    5.  
    1.  
    1.  
 
 u3  =
 
    1.  
    0.  
    1.  
  - 4.  
 
 u4  =
 
    5.  
  - 3.  
  - 1.  
    1.  
 
 x  =
 
    10.  
  - 8.   
    2.   
    0.   
 
 
 u1=   
 
    0.  
    1.  
  - 4.  
  - 1.  
 
 u2=   
 
    3.  
    5.  
    1.  
    1.  
 
 u3=   
 
    1.  
    0.  
    1.  
  - 4.  
 
 u4=   
 
    5.  
  - 3.  
  - 1.  
    1.  
 
 x=   
 
    10.  
  - 8.   
    2.   
    0.   
 
 
 The vector in span{u4}=((x.u4)/(u4.u4))*u4   
 
 a1  =
 
    72.  
 
 a2  =
 
    36.  
 
 
    10.  
  - 6.   
  - 2.   
    2.   
 
 
 Therefore, the vector in span{u1 u2 u3}=x-2*u4   
 
 
    0.  
  - 2.  
    4.  
  - 2.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.3.7/6_3_7.sce #
 
 Vectors u1 u2 and y are   
 
 u1  =
 
    1.  
    3.  
  - 2.  
 
 u2  =
 
    5.  
    1.  
    4.  
 
 y  =
 
    1.  
    3.  
    5.  
 
 
 u1=   
 
    1.  
    3.  
  - 2.  
 
 u2=   
 
    5.  
    1.  
    4.  
 
 y=   
 
    1.  
    3.  
    5.  
 
 
 u1.u2=   
 
 a  =
 
    0.  
 
 
 =   
 
    0.  
 
 
 Hence, {u1 u2} form an orthogonal basis.   
 
 
 Let W=span{u1 u2}   
 
 
 Therefore, projection of y on W is:   
 
 
 ((y.u1)/(u1.u1))*u1+((y.u2)/(u2.u2))*u2   
 
 a1  =
 
    0.  
 
 a2  =
 
    14.  
 
 b1  =
 
    28.  
 
 b2  =
 
    42.  
 
 
 =   
 
    0.  
    0.  
    0.  
 
 +   
 
    3.3333333  
    0.6666667  
    2.6666667  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.4.13/6_4_13.sce #
 
 QR decomposition of a matrix   
 
 
 given matrix A=   
 
 a  =
 
    5.    9.  
    1.    7.  
  - 3.  - 5.  
    1.    5.  
 
 
    5.    9.  
    1.    7.  
  - 3.  - 5.  
    1.    5.  
 
 
 given matrix Q=   
 
 q  =
 
    0.8333333  - 0.1666667  
    0.1666667    0.8333333  
  - 0.5          0.1666667  
    0.1666667    0.5        
 
 
    0.8333333  - 0.1666667  
    0.1666667    0.8333333  
  - 0.5          0.1666667  
    0.1666667    0.5        
 
 
 Therefore, R=   
 
 s  =
 
    6.    12.  
    0.    6.   
 
 
    6.    12.  
    0.    6.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.4.1/6_4_1.sce #
 
 to orthogonalise the given vectors using Gram-Schimdt orthogonalisation   
 
 x1  =
 
    3.  
    0.  
  - 1.  
 
 x2  =
 
    8.  
    5.  
  - 6.  
 
 
 x1=   
 
    3.  
    0.  
  - 1.  
 
 x2=   
 
    8.  
    5.  
  - 6.  
 
 
 Let v1=x1   
 
 v1  =
 
    3.  
    0.  
  - 1.  
 
 
 v2=x2-((x2.v1)/(v1.v1))*v1   
 
 a1  =
 
    30.  
 
 a2  =
 
    10.  
 
 p  =
 
    9.  
    0.  
  - 3.  
 
 v2  =
 
  - 1.  
    5.  
  - 3.  
 
 
 =   
 
    8.  
    5.  
  - 6.  
 
 -   
 
    9.  
    0.  
  - 3.  
 
 
 =   
 
  - 1.  
    5.  
  - 3.  
 
 
 Thus, an orthogonal basis is:   
 
 
    3.  
    0.  
  - 1.  
 
  - 1.  
    5.  
  - 3.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.4.7/6_4_7.sce #
 
 to orthogonalise the given vectors using Gram-Schimdt orthogonalisation   
 
 x1  =
 
    2.  
  - 5.  
    1.  
 
 x2  =
 
    4.  
  - 1.  
    2.  
 
 
 x1=   
 
    2.  
  - 5.  
    1.  
 
 x2=   
 
    4.  
  - 1.  
    2.  
 
 
 Let v1=x1   
 
 v1  =
 
    2.  
  - 5.  
    1.  
 
 
 v2=x2-((x2.v1)/(v1.v1))*v1   
 
 a1  =
 
    15.  
 
 a2  =
 
    30.  
 
 p  =
 
    1.   
  - 2.5  
    0.5  
 
 v2  =
 
    3.   
    1.5  
    1.5  
 
 
 =   
 
    4.  
  - 1.  
    2.  
 
 -   
 
    1.   
  - 2.5  
    0.5  
 
 
 =   
 
    3.   
    1.5  
    1.5  
 
 
 Thus, an orthogonal basis is:   
 
 
    2.  
  - 5.  
    1.  
 
    3.   
    1.5  
    1.5  
 
 
 Normalizing v1 and v2, we get   
 
 s1  =
 
    5.4772256  
 
 s2  =
 
    3.6742346  
 
 
    0.3651484  
  - 0.9128709  
    0.1825742  
 
    0.8164966  
    0.4082483  
    0.4082483  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.5.13/6_5_13.sce #
 
 To determine if u is the least square solution to Ax=b   
 
 
 Given   
 
 a  =
 
    3.    4.  
  - 2.    1.  
    3.    4.  
 
 
 A=   
 
    3.    4.  
  - 2.    1.  
    3.    4.  
 
 b  =
 
    11.  
  - 9.   
    5.   
 
 
 b=   
 
    11.  
  - 9.   
    5.   
 
 u  =
 
    5.  
  - 1.  
 
 v  =
 
    5.  
  - 2.  
 
 
 u=   
 
    5.  
  - 1.  
 
 v=   
 
    5.  
  - 2.  
 
 
 Au=   
 
 
    11.  
  - 11.  
    11.  
 
 c  =
 
    0.  
    2.  
  - 6.  
 
 
 b-Au=   
 
    0.  
    2.  
  - 6.  
 
 
 ||b-Au||=   
 
 
    6.3245553  
 
 
 Av=   
 
 
    7.   
  - 12.  
    7.   
 
 d  =
 
    4.  
    3.  
  - 2.  
 
 
 b-Av=   
 
    4.  
    3.  
  - 2.  
 
 
 ||b-Av||=   
 
 
    5.3851648  
 
 
 Since Av is more r to A than Au, u is not the least square solution.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.5.1/6_5_1.sce #
 
 The co-efficient matrix is:   
 
 a  =
 
  - 1.    2.  
    2.  - 3.  
  - 1.    3.  
 
 
 A=   
 
  - 1.    2.  
    2.  - 3.  
  - 1.    3.  
 
 
 The RHS is:   
 
 b  =
 
    4.  
    1.  
    2.  
 
 
    4.  
    1.  
    2.  
 
 
 Product of transpose of A and A=   
 
 p1  =
 
    6.   - 11.  
  - 11.    22.  
 
 
    6.   - 11.  
  - 11.    22.  
 
 
 Product of transpose of A and b=   
 
 p2  =
 
  - 4.   
    11.  
 
 
  - 4.   
    11.  
 
 
 Hence, the solution is:   
 
 p  =
 
    3.  
    2.  
 
 
    3.  
    2.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.5.7/6_5_7.sce #
 
 The co-efficient matrix is:   
 
 a  =
 
    1.  - 2.  
  - 1.    2.  
    0.    3.  
    2.    5.  
 
 
 A=   
 
    1.  - 2.  
  - 1.    2.  
    0.    3.  
    2.    5.  
 
 
 The RHS is:   
 
 b  =
 
    3.  
    1.  
  - 4.  
    2.  
 
 
 b=   
 
    3.  
    1.  
  - 4.  
    2.  
 
 
 Product of transpose of A and A=   
 
 p1  =
 
    6.    6.   
    6.    42.  
 
 
    6.    6.   
    6.    42.  
 
 
 Product of transpose of A and b=   
 
 p2  =
 
    6.  
  - 6.  
 
 
 Forming an augmented matrix to solve the normal equations   
 
 p  =
 
    6.    6.     6.  
    6.    42.  - 6.  
 
 
    6.    6.     6.  
    6.    42.  - 6.  
 
 
 performing row operations   
 
 
 R2=R2-R1   
 
 p  =
 
    6.    6.     6.   
    0.    36.  - 12.  
 
 
    6.    6.     6.   
    0.    36.  - 12.  
 
 
 R1=R1/6 and R2=R2/36   
 
 p  =
 
    1.    1.     1.   
    0.    36.  - 12.  
 
 p  =
 
    1.    1.    1.         
    0.    1.  - 0.3333333  
 
 
    1.    1.    1.         
    0.    1.  - 0.3333333  
 
 
 R1=R1-R2   
 
 p  =
 
    1.    0.    1.3333333  
    0.    1.  - 0.3333333  
 
 
    1.    0.    1.3333333  
    0.    1.  - 0.3333333  
 
 
 Hence, the solution is:   
 
 
    1.3333333  
  - 0.3333333  
 
 x  =
 
    1.3333333  
  - 0.3333333  
 
 
 The least square error is=||Ax-b||   
 
 
 Ax-b=   
 
 
  - 1.  
  - 3.  
    3.  
  - 1.  
 
 c  =
 
  - 1.  
  - 3.  
    3.  
  - 1.  
 
 s  =
 
    0.  
 
 s  =
 
    1.  
 s  =
 
    10.  
 s  =
 
    19.  
 s  =
 
    20.  
 
 
 ||Ax-b||=   
 
 
    4.472136  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH6/EX6.6.1/6_6_1.sce #
 
 To obtain a least sqaure line from the given data   
 
 
 Placing the x coordinates of the data in second column of matrix X we get:   
 
 x  =
 
    1.    0.  
    1.    1.  
    1.    2.  
    1.    3.  
 
 
 X=   
 
    1.    0.  
    1.    1.  
    1.    2.  
    1.    3.  
 
 
 Placing the y coordinates in y vector   
 
 y  =
 
    1.  
    1.  
    2.  
    2.  
 
 
 y=   
 
    1.  
    1.  
    2.  
    2.  
 
 
 Product of transpose of X and X=   
 
 p1  =
 
    4.    6.   
    6.    14.  
 
 
    4.    6.   
    6.    14.  
 
 
 Product of transpose of X and y=   
 
 p2  =
 
    6.   
    11.  
 
 
    6.   
    11.  
 
 
 The least square solution =   
 
 
    0.9  
    0.4  
 
 p  =
 
    0.9  
    0.4  
 
 
 Hence, the least square line is:   
 
 
 y   
 
 =   
 
    0.9  
 
 +   
 
    0.4  
 
 x   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH7/EX7.1.13/7_1_13.sce #
 
 To diagonalize the given matrix A   
 
 a  =
 
    3.    1.  
    1.    3.  
 
 
 A=   
 
    3.    1.  
    1.    3.  
 
 eig  =
 
    2.  
    4.  
 
 
 Eigen values of A are:   
 
 
    2.  
    4.  
 
 
 for lambda=4   
 
 
 A-4I=   
 
 
  - 1.    1.  
    1.  - 1.  
 
 b  =
 
  - 1.    1.  
    1.  - 1.  
 
 
 To find the eigenvector, form an augmented matrix.   
 
 c  =
 
  - 1.    1.    0.  
    1.  - 1.    0.  
 
 
 performing row operations   
 
 
  - 1.    1.    0.  
    1.  - 1.    0.  
 
 c  =
 
  - 1.    1.    0.  
    0.    0.    0.  
 
 
  - 1.    1.    0.  
    0.    0.    0.  
 
 
 With x2 as free variable, x1=x2   
 
 
 Hence a basis for the eigenspace is:   
 
 d  =
 
    1.  
    1.  
 
 
    1.  
    1.  
 
 
 Upon normalizing   
 
 
    0.7071068  
    0.7071068  
 
 u1  =
 
    0.7071068  
    0.7071068  
 
 
 for lambda=2   
 
 
 A-2I=   
 
 b  =
 
    1.    1.  
    1.    1.  
 
 
    1.    1.  
    1.    1.  
 
 
 To find the eigenvector, form an augmented matrix.   
 
 c  =
 
    1.    1.    0.  
    1.    1.    0.  
 
 
 performing row operations   
 
 
    1.    1.    0.  
    1.    1.    0.  
 
 c  =
 
    1.    1.    0.  
    0.    0.    0.  
 
 
    1.    1.    0.  
    0.    0.    0.  
 
 
 With x2 as free variable, x1=-x2   
 
 
 Hence a basis for the eigenspace is:   
 
 d  =
 
  - 1.  
    1.  
 
 
  - 1.  
    1.  
 
 
 Upon normalizing   
 
 
  - 0.7071068  
    0.7071068  
 
 u2  =
 
  - 0.7071068  
    0.7071068  
 
 
 Matrix P=   
 
 p  =
 
    0.7071068  - 0.7071068  
    0.7071068    0.7071068  
 
 
    0.7071068  - 0.7071068  
    0.7071068    0.7071068  
 
 
 The corresponding matrix D=   
 
 
    4.    0.  
    0.    2.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH7/EX7.1.19/7_1_19.sce #
 
 PD decomposition of a matrix A   
 
 a  =
 
    3.  - 2.    4.  
  - 2.    6.    2.  
    4.    2.    3.  
 
 
 A=   
 
    3.  - 2.    4.  
  - 2.    6.    2.  
    4.    2.    3.  
 
 
 Eigenvalues of A are   
 
 eig  =
 
  - 2.  
    7.  
    7.  
 
 
  - 2.  
    7.  
    7.  
 
 
 for lambda =   
 
    7.  
 
 
 A-(lambda)I=   
 
 b  =
 
  - 4.  - 2.    4.  
  - 2.  - 1.    2.  
    4.    2.  - 4.  
 
 
  - 4.  - 2.    4.  
  - 2.  - 1.    2.  
    4.    2.  - 4.  
 
 
 To find eigenvector, form an augmented matrix   
 
 c  =
 
  - 4.  - 2.    4.    0.  
  - 2.  - 1.    2.    0.  
    4.    2.  - 4.    0.  
 
 
  - 4.  - 2.    4.    0.  
  - 2.  - 1.    2.    0.  
    4.    2.  - 4.    0.  
 
 
 performing row operations   
 
 c  =
 
  - 4.  - 2.           4.           0.  
    0.    2.220D-15  - 8.882D-16    0.  
    4.    2.         - 4.           0.  
 
 c  =
 
  - 4.  - 2.           4.           0.  
    0.    2.220D-15  - 8.882D-16    0.  
    0.  - 8.882D-16    3.553D-15    0.  
 
 
  - 4.  - 2.           4.           0.  
    0.    2.220D-15  - 8.882D-16    0.  
    0.  - 8.882D-16    3.553D-15    0.  
 
 
 With x2 and x3 as free variables, we get two vectors.   
 
 
 x1=-.5x2+x3   
 
 
 Thus, the two vectors are   
 
 v1  =
 
  - 1.  
    2.  
    0.  
 
 v2  =
 
    1.  
    0.  
    1.  
 
 
  - 1.  
    2.  
    0.  
 
    1.  
    0.  
    1.  
 
 
 Orthogonalizing v1 and v2   
 
 
 Let x1=v1   
 
 
 x2=v2-((v2.v1)/(v1.v1))*v1   
 
 x1  =
 
  - 1.  
    2.  
    0.  
 
 a1  =
 
  - 1.  
 
 a2  =
 
    5.  
 
 x2  =
 
    0.8  
    0.4  
    1.   
 
 x1  =
 
  - 0.4472136  
    0.8944272  
    0.         
 
 x1  =
 
    0.5962848  
    0.2981424  
    0.7453560  
 
 
 An orthonormal basis is:   
 
 
    0.5962848  
    0.2981424  
    0.7453560  
 
    0.8  
    0.4  
    1.   
 
 
 for lambda=   
 
  - 2.  
 
 
 A-(lambda)I=   
 
 b  =
 
    5.  - 2.    4.  
  - 2.    8.    2.  
    4.    2.    5.  
 
 
    5.  - 2.    4.  
  - 2.    8.    2.  
    4.    2.    5.  
 
 
 To find eigenvector, form an augmented matrix   
 
 c  =
 
    5.  - 2.    4.    0.  
  - 2.    8.    2.    0.  
    4.    2.    5.    0.  
 
 
    5.  - 2.    4.    0.  
  - 2.    8.    2.    0.  
    4.    2.    5.    0.  
 
 
 performing row operations   
 
 c  =
 
    5.  - 2.     4.     0.  
    0.    7.2    3.6    0.  
    4.    2.     5.     0.  
 
 c  =
 
    5.  - 2.     4.     0.  
    0.    7.2    3.6    0.  
    0.    3.6    1.8    0.  
 
 
    5.  - 2.     4.     0.  
    0.    7.2    3.6    0.  
    0.    3.6    1.8    0.  
 
 c  =
 
    5.  - 2.     4.           0.  
    0.    7.2    3.6          0.  
    0.    0.   - 2.220D-16    0.  
 
 
    5.  - 2.     4.           0.  
    0.    7.2    3.6          0.  
    0.    0.   - 2.220D-16    0.  
 
 c  =
 
    1.  - 0.4    0.8          0.  
    0.    7.2    3.6          0.  
    0.    0.   - 2.220D-16    0.  
 
 c  =
 
    1.  - 0.4    0.8          0.  
    0.    1.     0.5          0.  
    0.    0.   - 2.220D-16    0.  
 
 
    1.  - 0.4    0.8          0.  
    0.    1.     0.5          0.  
    0.    0.   - 2.220D-16    0.  
 
 c  =
 
    1.    0.    1.           0.  
    0.    1.    0.5          0.  
    0.    0.  - 2.220D-16    0.  
 
 
    1.    0.    1.           0.  
    0.    1.    0.5          0.  
    0.    0.  - 2.220D-16    0.  
 
 
 With x3 as free variable   
 
 
 x1=x3 and x2=-.5x3   
 
 
 Thus a basis for the eigenspace is:   
 
 v3  =
 
    1.   
  - 0.5  
    1.   
 
 
    1.   
  - 0.5  
    1.   
 
 
 upon normalizing   
 
 v3  =
 
    0.6666667  
  - 0.3333333  
    0.6666667  
 
 
    0.6666667  
  - 0.3333333  
    0.6666667  
 
 
 Thus, matrix P=   
 
 
    0.5962848    0.8    0.6666667  
    0.2981424    0.4  - 0.3333333  
    0.7453560    1.     0.6666667  
 
 
 Corresponding matrix D=   
 
 
    7.    0.    0.  
    0.    7.    0.  
    0.    0.  - 2.  
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH7/EX7.1.1/7_1_1.sce #
 
 To check if the given 2X2 matrix is symmetric   
 
 a  =
 
    3.    5.  
    5.  - 7.  
 
 
 A=   
 
    3.    5.  
    5.  - 7.  
 
 
 A is a symmetric matrix because the (1,2) and(2,1) entries match.   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH7/EX7.1.7/7_1_7.sce #
 
 To show that the given matrix P is orthogonal.   
 
 p  =
 
    0.6    0.8  
    0.8  - 0.6  
 
 
 P=   
 
    0.6    0.8  
    0.8  - 0.6  
 
 
 P is composed of two vectors.   
 
 p1  =
 
    0.6  
    0.8  
 
 p2  =
 
    0.8  
  - 0.6  
 
 
 p1=   
 
    0.6  
    0.8  
 
 p2=   
 
    0.8  
  - 0.6  
 
 
 To show that the columns are orthonormal   
 
 
 p1.p2=   
 
 s  =
 
    0.  
 
 r  =
 
    0.6    0.8  
 
 
 =   
 
    0.6    0.8  
 
 *   
 
    0.8  
  - 0.6  
 
 
 =   
 
    0.  
 
 
 The columns of P are othonormal   
 
 
 ||p1||=   
 
 
    1.  
 
 
 ||p2||=   
 
 
    1.  
 
 
 Hence, ||p1||=||p2||=1. Thus P is an orthogonal matrix   
 
grepthis#Linear_Algebra_And_Its_Applications_D._C._Lay_26/CH7/EX7.2.1/7_2_1.sce #
 
 given matrix A and vector x   
 
 a  =
 
    5.           0.3333333  
    0.3333333    1.         
 
 
 A=   
 
    5.           0.3333333  
    0.3333333    1.         
 
 x  =
 
    6.  
    1.  
 
 
 x=   
 
    6.  
    1.  
 
 
 Product of transpose of x and A and x=   
 
 p  =
 
    185.  
 
 
    185.  
 
 
 New value of vector x=   
 
 x  =
 
    1.  
    3.  
 
 
    1.  
    3.  
 
 
 Product of transpose of x and A and x=   
 
 p  =
 
    16.  
 
 
    16.  
 
